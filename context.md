# Context: Sistema de MigraciÃ³n MongoDB â†’ PostgreSQL

**Ãšltima actualizaciÃ³n:** 2025-01-19  
**Estado del proyecto:** En desarrollo activo (2/8 colecciones migradas)  
**PropÃ³sito de este documento:** Continuidad tÃ©cnica y de metodologÃ­a de trabajo

---

## ğŸ“– Tabla de Contenidos

1. [CÃ³mo Usar Este Documento](#cÃ³mo-usar-este-documento)
2. [FilosofÃ­a de Trabajo](#filosofÃ­a-de-trabajo)
   - [Estilo de ComunicaciÃ³n](#estilo-de-comunicaciÃ³n)
   - [MetodologÃ­a de ResoluciÃ³n](#metodologÃ­a-de-resoluciÃ³n)
   - [Estilo de CÃ³digo](#estilo-de-cÃ³digo)
3. [Estado Actual del Proyecto](#estado-actual-del-proyecto)
4. [Arquitectura TÃ©cnica](#arquitectura-tÃ©cnica)
   - [TopologÃ­a de Datos](#topologÃ­a-de-datos)
   - [PatrÃ³n de Schema](#patrÃ³n-de-schema)
   - [Flujo de MigraciÃ³n](#flujo-de-migraciÃ³n)
5. [Decisiones TÃ©cnicas](#decisiones-tÃ©cnicas)
6. [Estructura de CÃ³digo](#estructura-de-cÃ³digo)
7. [Convenciones](#convenciones)
8. [Workflow de AnÃ¡lisis](#workflow-de-anÃ¡lisis)
9. [Agregar Nueva ColecciÃ³n](#agregar-nueva-colecciÃ³n)
10. [Testing](#testing)
11. [ConfiguraciÃ³n de Performance](#configuraciÃ³n-de-performance)
12. [Troubleshooting](#troubleshooting)
13. [MÃ©tricas y Recursos](#mÃ©tricas-y-recursos)

---

## CÃ³mo Usar Este Documento

Este documento es la **memoria tÃ©cnica del proyecto**. Su propÃ³sito es triple:

1. **Para Asistentes IA**: Entender el contexto completo sin necesidad de explorar todo el cÃ³digo
2. **Para Desarrolladores**: Referencia rÃ¡pida de decisiones, patrones y convenciones
3. **Para Continuidad**: Permitir que cualquier persona retome el trabajo sin perder el hilo

### Estructura de Lectura Recomendada

- **Primera vez**: Lee completo de inicio a fin (30-40 minutos)
- **Agregar colecciÃ³n nueva**: Secciones 8, 9, 6, 10 (en ese orden)
- **Debugging**: SecciÃ³n 12 (Troubleshooting) primero, luego contexto especÃ­fico
- **OptimizaciÃ³n**: Secciones 11, 13

### Convenciones de Formato

- âœ… = Completado/Implementado
- âš ï¸ = AtenciÃ³n/Cuidado requerido
- ğŸ”§ = En progreso/trabajo activo
- ğŸ“Š = MÃ©tricas/datos medidos
- ğŸ’¡ = Insight/decisiÃ³n importante
- ğŸš« = Anti-patrÃ³n/no hacer

---

## FilosofÃ­a de Trabajo

### Estilo de ComunicaciÃ³n

**Tono**: TÃ©cnico-pedagÃ³gico, profesional pero accesible.

**Principios**:
- Explicar el "por quÃ©", no solo el "quÃ©" y "cÃ³mo"
- Documentar trade-offs de cada decisiÃ³n importante
- Usar ejemplos concretos del proyecto (no genÃ©ricos)
- Anticipar preguntas del lector

**Ejemplo de buena explicaciÃ³n**:
```
âŒ Mal: "Usamos BATCH_SIZE = 2000"
âœ… Bien: "BATCH_SIZE = 2000 balancea memoria vs velocidad. 
         Mayor = mÃ¡s rÃ¡pido pero riesgo de OOM.
         Menor = mÃ¡s lento pero mÃ¡s seguro.
         2000 procesa ~129k docs en 20min sin problemas."
```

### MetodologÃ­a de ResoluciÃ³n

**Flujo estÃ¡ndar para agregar una colecciÃ³n**:

1. **AnÃ¡lisis** (30-40% del tiempo)
   - Exportar sample: `python export_sample.py <collection> 200`
   - AnÃ¡lisis manual del JSON exportado
   - Identificar patrones de normalizaciÃ³n
   - Decidir quÃ© va a tablas vs JSONB

2. **DiseÃ±o** (20-30% del tiempo)
   - DiseÃ±ar schema PostgreSQL
   - Definir claves primarias y forÃ¡neas
   - Mapear campos MongoDB â†’ PostgreSQL

3. **ImplementaciÃ³n** (30-40% del tiempo)
   - Crear tablas en `dbsetup.py`
   - Implementar migrador heredando de `BaseMigrator`
   - Testing iterativo con subconjuntos

4. **ValidaciÃ³n** (10% del tiempo)
   - Verificar conteos: MongoDB vs PostgreSQL
   - Verificar integridad referencial
   - Probar queries representativas

### Estilo de CÃ³digo

**Principios fundamentales**:

1. **ExplÃ­cito > ImplÃ­cito**
   ```python
   # âŒ Mal
   def process(d):
       return d.get('id')
   
   # âœ… Bien
   def extract_user_id_from_document(document: dict) -> str:
       """Extrae user_id desde documento MongoDB."""
       return document.get('id')
   ```

2. **Docstrings completos**
   - QuÃ© hace la funciÃ³n
   - ParÃ¡metros con tipos y significado
   - Retorno con estructura esperada
   - Ejemplo de uso si no es obvio

3. **Nombres semÃ¡nticos**
   ```python
   # âŒ Mal: nombres tÃ©cnicos
   mongo_id, record_id
   
   # âœ… Bien: nombres de negocio
   process_id, listbuilder_id
   ```

4. **SeparaciÃ³n de responsabilidades**
   - MÃ©todos pÃºblicos: Interfaz (quÃ© hace)
   - MÃ©todos privados: ImplementaciÃ³n (cÃ³mo lo hace)
   - Un mÃ©todo = una responsabilidad clara

---

## Estado Actual del Proyecto

### VisiÃ³n General
Sistema de migraciÃ³n desde MongoDB (`mesa4core`) a PostgreSQL (`mesamongo`). Objetivo: transformar documentos NoSQL anidados en modelo relacional normalizado.

### Razones de la MigraciÃ³n

1. **Integridad de Datos**: Implementar integridad referencial mediante claves forÃ¡neas y restricciones
2. **NormalizaciÃ³n**: Eliminar la duplicaciÃ³n de datos inherente al modelo desnormalizado de MongoDB
3. **Consultas Complejas**: Habilitar JOINs eficientes y consultas relacionales complejas
4. **EstandarizaciÃ³n**: Consolidar entidades compartidas (usuarios, Ã¡reas, clientes) en tablas de Ãºnica fuente de verdad

### Colecciones Migradas

| ColecciÃ³n | Schema | Documentos | Estado | Tiempo | Docs/seg |
|-----------|--------|------------|--------|--------|----------|
| âœ… lml_processes_mesa4core | lml_processes | ~129,000 | Completo | ~20 min | ~107 |
| âœ… lml_listbuilder_mesa4core | lml_listbuilder | ~200 | Completo | <1 min | N/A |
| ğŸ”§ [Pendiente] | - | - | - | - | - |

### PrÃ³ximos Pasos Inmediatos

1. âœ… Separar setup de migraciÃ³n (dbsetup.py â‰  mongomigra.py)
2. âœ… Sistema de carga dinÃ¡mica de migradores
3. ğŸ”§ Migrar siguiente colecciÃ³n (TBD)
4. ğŸ”§ Implementar tests de integridad

---

## Arquitectura TÃ©cnica

### TopologÃ­a de Datos

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      MongoDB (mesa4core)        â”‚
                    â”‚    ~N colecciones anidadas      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                         TransformaciÃ³n
                         (mongomigra.py)
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PostgreSQL (mesamongo)        â”‚
                    â”‚                                 â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                    â”‚  â”‚   Schema: public        â”‚   â”‚
                    â”‚  â”‚   (Entidades Comunes)   â”‚   â”‚
                    â”‚  â”‚   - users               â”‚   â”‚
                    â”‚  â”‚   - customers           â”‚   â”‚
                    â”‚  â”‚   - areas/subareas      â”‚   â”‚
                    â”‚  â”‚   - roles/groups        â”‚   â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                    â”‚                                 â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                    â”‚  â”‚  Schema: lml_processes  â”‚   â”‚
                    â”‚  â”‚  (Datos EspecÃ­ficos)    â”‚   â”‚
                    â”‚  â”‚  - main                 â”‚   â”‚
                    â”‚  â”‚  - movements            â”‚   â”‚
                    â”‚  â”‚  - documents            â”‚   â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                    â”‚                                 â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                    â”‚  â”‚ Schema: lml_listbuilder â”‚   â”‚
                    â”‚  â”‚  (Configs UI)           â”‚   â”‚
                    â”‚  â”‚  - main                 â”‚   â”‚
                    â”‚  â”‚  - fields               â”‚   â”‚
                    â”‚  â”‚  - items                â”‚   â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PatrÃ³n de Schema

**Arquitectura HÃ­brida**: SeparaciÃ³n entre entidades compartidas y especÃ­ficas.

#### Schema Public (Entidades Compartidas)
Aloja entidades que se reutilizan a travÃ©s de mÃºltiples colecciones:

```sql
-- Tabla de usuarios (referenciada por TODAS las colecciones)
CREATE TABLE public.users (
    id VARCHAR(255) PRIMARY KEY,
    email VARCHAR(255),  -- Sin UNIQUE (ver Decisiones TÃ©cnicas)
    firstname VARCHAR(255),
    lastname VARCHAR(255),
    area_id VARCHAR(255) REFERENCES public.areas(id),
    subarea_id VARCHAR(255) REFERENCES public.subareas(id),
    role_id VARCHAR(255) REFERENCES public.roles(id)
);

-- Clientes (entidad de negocio central)
CREATE TABLE public.customers (
    id VARCHAR(255) PRIMARY KEY
);

-- JerarquÃ­a organizacional
CREATE TABLE public.areas (
    id VARCHAR(255) PRIMARY KEY,
    name VARCHAR(255)
);

CREATE TABLE public.subareas (
    id VARCHAR(255) PRIMARY KEY,
    name VARCHAR(255)
);
```

#### Schemas EspecÃ­ficos por ColecciÃ³n
Cada colecciÃ³n MongoDB obtiene su propio schema:

```sql
-- Schema para lml_processes
CREATE SCHEMA IF NOT EXISTS lml_processes;

CREATE TABLE lml_processes.main (
    process_id VARCHAR(255) PRIMARY KEY,  -- Semantic naming!
    process_number VARCHAR(255),
    customer_id VARCHAR(255) REFERENCES public.customers(id),
    created_by_user_id VARCHAR(255) REFERENCES public.users(id),
    -- ... mÃ¡s columnas
);

CREATE TABLE lml_processes.movements (
    id SERIAL PRIMARY KEY,
    process_id VARCHAR(255) REFERENCES lml_processes.main(process_id),
    movement_at TIMESTAMP,
    -- ... mÃ¡s columnas
);
```

### Flujo de MigraciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FLUJO COMPLETO                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. SETUP (Una sola vez)
   â†“
   python dbsetup.py
   â†“
   Crea todos los schemas y tablas

2. MIGRACIÃ“N (Por colecciÃ³n)
   â†“
   python mongomigra.py
   â†“
   Seleccionar colecciÃ³n del menÃº
   â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  IteraciÃ³n sobre documentos (batches)       â”‚
   â”‚                                              â”‚
   â”‚  Por cada documento:                         â”‚
   â”‚  1. extract_shared_entities()                â”‚
   â”‚     â†’ Inserta/actualiza public.*            â”‚
   â”‚     â†’ Usa cachÃ© para evitar duplicados      â”‚
   â”‚                                              â”‚
   â”‚  2. extract_data()                           â”‚
   â”‚     â†’ Extrae datos especÃ­ficos              â”‚
   â”‚     â†’ Retorna estructura normalizada        â”‚
   â”‚                                              â”‚
   â”‚  3. Acumular en batches                      â”‚
   â”‚                                              â”‚
   â”‚  Cada BATCH_SIZE documentos:                 â”‚
   â”‚  4. insert_batches()                         â”‚
   â”‚     â†’ executemany() para bulk insert        â”‚
   â”‚     â†’ commit a PostgreSQL                   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
   MigraciÃ³n completa
```

### Â¿Por quÃ© HÃ­brido vs. Schema Ãšnico?

| Criterio | HÃ­brido (âœ… Elegido) | Schema Ãšnico (ğŸš« Descartado) |
|----------|---------------------|---------------------------|
| OrganizaciÃ³n | Clara separaciÃ³n compartido/especÃ­fico | Todo mezclado |
| Escalabilidad | Sin colisiones de nombres | Risk de colisiÃ³n: lml_processes.main vs lml_listbuilder.main |
| Mantenibilidad | FÃ¡cil entender propiedad de datos | DifÃ­cil saber quÃ© tabla usa quÃ© colecciÃ³n |
| Foreign Keys | Simples: `REFERENCES public.users` | Complejas: referencias cruzadas |
| Futuro | Agregar colecciÃ³n = nuevo schema | Agregar colecciÃ³n = posibles conflictos |

---

## Decisiones TÃ©cnicas

### 1. Full Refresh vs Incremental Sync

**DecisiÃ³n**: Full Refresh (recrear datos cada vez)

**JustificaciÃ³n**:
- MongoDB es sistema legacy, datos histÃ³ricos no cambian
- SincronizaciÃ³n incremental requiere:
  - Tracking de `updatedAt` (no confiable en origen)
  - LÃ³gica de merge/upsert compleja
  - Riesgo de inconsistencias
- Full refresh garantiza consistencia total

**Trade-offs**:
```
Full Refresh:
  âœ… Siempre consistente con origen
  âœ… LÃ³gica simple (solo INSERTs)
  âœ… Idempotente (re-ejecutable)
  ğŸš« Tiempo de downtime en cada migraciÃ³n

Incremental:
  âœ… RÃ¡pido para updates pequeÃ±os
  ğŸš« Complejidad alta
  ğŸš« Requiere auditorÃ­a de cambios
  ğŸš« Riesgo de drift entre sistemas
```

**ImplementaciÃ³n**:
```python
# Idempotencia via ON CONFLICT
INSERT INTO public.users (id, email, ...) 
VALUES (%s, %s, ...) 
ON CONFLICT (id) DO NOTHING;
```

### 2. EliminaciÃ³n de UNIQUE(email) en public.users

**DecisiÃ³n**: `email` sin constraint UNIQUE

**Razones**:
1. **Datos sucios en origen**: MongoDB tiene usuarios con emails duplicados
2. **Historia de cambios**: Mismo usuario puede tener mÃºltiples emails a lo largo del tiempo
3. **IDs son PK real**: `user.id` es el identificador Ãºnico verdadero

**Ejemplo del problema**:
```
Usuario A: {id: "USR001", email: "juan@ejemplo.com"}
Usuario B: {id: "USR002", email: "juan@ejemplo.com"}  # Mismo email!

Con UNIQUE(email) â†’ Error de constraint
Sin UNIQUE(email) â†’ Ambos se insertan correctamente
```

**Consecuencias**:
- âœ… MigraciÃ³n no falla por duplicados
- âš ï¸ Queries por email pueden retornar mÃºltiples usuarios
- ğŸ’¡ Siempre usar `user.id` como referencia, no email

### 3. Estrategia de ON CONFLICT

**DecisiÃ³n**: Usar `ON CONFLICT` pero diferenciado por tipo de tabla

**Para tablas compartidas (public.*)**:
```sql
-- OpciÃ³n A: DO NOTHING (elegida)
INSERT INTO public.users (...) VALUES (...)
ON CONFLICT (id) DO NOTHING;

-- Â¿Por quÃ© NO DO UPDATE?
-- Porque el primer documento que procesamos puede no tener
-- los datos mÃ¡s actualizados. DO NOTHING asegura que el
-- primer insert completo se preserva.
```

**Para tablas especÃ­ficas con PK natural**:
```sql
-- TambiÃ©n DO NOTHING
INSERT INTO lml_processes.main (process_id, ...) VALUES (...)
ON CONFLICT (process_id) DO NOTHING;
```

**Para tablas relacionadas sin constraint Ãºnico**:
```sql
-- Sin ON CONFLICT (pueden haber duplicados legÃ­timos)
INSERT INTO lml_processes.movements (process_id, movement_at, ...) 
VALUES (...);
```

### 4. NormalizaciÃ³n vs JSON

**DecisiÃ³n**: Matriz de decisiÃ³n basada en criterios

| Criterio | â†’ Tabla Normalizada | â†’ Campo JSONB |
|----------|---------------------|---------------|
| Â¿Se consulta en WHERE? | âœ… | ğŸš« |
| Â¿Tiene FK a public.*? | âœ… | ğŸš« |
| Â¿Estructura fija? | âœ… | ğŸš« |
| Â¿1:N con muchos registros? | âœ… | ğŸš« |
| Â¿Estructura variable? | ğŸš« | âœ… |
| Â¿Solo se muestra completo? | ğŸš« | âœ… |
| Â¿Metadata tÃ©cnica? | ğŸš« | âœ… |
| Â¿1:N con pocos items (<10)? | ğŸš« | âœ… |

**Ejemplos del proyecto**:

```python
# âœ… Tabla normalizada: movements
# RazÃ³n: 1:N con muchos registros, se consultan, tienen timestamps
CREATE TABLE lml_processes.movements (
    id SERIAL PRIMARY KEY,
    process_id VARCHAR(255) REFERENCES lml_processes.main,
    movement_at TIMESTAMP,
    destination_id VARCHAR(255)
);

# âœ… JSONB: gqlVariables en listbuilder
# RazÃ³n: Estructura variable, metadata tÃ©cnica, solo se usa completo
CREATE TABLE lml_listbuilder.main (
    listbuilder_id VARCHAR(255) PRIMARY KEY,
    gql_variables JSONB,  -- Variable structure
    ...
);

# ğŸš« Anti-patrÃ³n: NO hacer esto
CREATE TABLE bad_example (
    id VARCHAR(255) PRIMARY KEY,
    user_data JSONB  -- âŒ Usuario deberÃ­a ser FK a public.users
);
```

---

## Estructura de CÃ³digo

### Ãrbol de Directorios

```
mongo_to_postgre/
â”œâ”€â”€ .env                      # Credenciales (NO committear)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt          # Dependencies: pymongo, psycopg2, python-dotenv
â”œâ”€â”€ README.md
â”œâ”€â”€ context.md               # Este documento
â”‚
â”œâ”€â”€ config.py                # â­ ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ MONGO_URI
â”‚   â”œâ”€â”€ POSTGRES_CONFIG
â”‚   â”œâ”€â”€ TABLE_NAMES
â”‚   â”œâ”€â”€ BATCH_SIZE
â”‚   â””â”€â”€ COLLECTIONS          # Mapeo colecciones â†’ schemas
â”‚
â”œâ”€â”€ dbsetup.py               # â­ Setup inicial (ejecutar UNA VEZ)
â”‚   â””â”€â”€ Crea schemas y tablas en PostgreSQL
â”‚
â”œâ”€â”€ mongomigra.py            # â­ Motor principal de migraciÃ³n
â”‚   â”œâ”€â”€ connect_to_mongo()
â”‚   â”œâ”€â”€ connect_to_postgres()
â”‚   â”œâ”€â”€ load_migrator_for_collection()  # Dynamic loading
â”‚   â”œâ”€â”€ show_collection_menu()
â”‚   â””â”€â”€ migrate_collection()            # Main loop
â”‚
â”œâ”€â”€ migrators/               # â­ Migradores especÃ­ficos por colecciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # BaseMigrator (interfaz abstracta)
â”‚   â”œâ”€â”€ lml_processes.py     # LmlProcessesMigrator
â”‚   â””â”€â”€ lml_listbuilder.py   # LmlListbuilderMigrator
â”‚
â”œâ”€â”€ export_sample.py         # ğŸ”§ Herramienta: exportar JSON de colecciÃ³n
â”œâ”€â”€ analyze_listbuilder.py   # ğŸ”§ Herramienta: analizar estructura
â”‚
â”œâ”€â”€ samples/                 # Muestras exportadas (para anÃ¡lisis)
â”‚   â”œâ”€â”€ lml_processes_mesa4core_sample.json
â”‚   â””â”€â”€ lml_listbuilder_mesa4core_sample.json
â”‚
â””â”€â”€ v1 lml_processes/        # VersiÃ³n legacy (referencia histÃ³rica)
    â”œâ”€â”€ mongomigra.py        # VersiÃ³n monolÃ­tica original
    â””â”€â”€ config.py
```

### Herramientas de AnÃ¡lisis

#### export_sample.py

**PropÃ³sito**: Exportar muestra de colecciÃ³n para anÃ¡lisis manual.

**Uso**:
```bash
python export_sample.py lml_listbuilder_mesa4core 200
```

**Output**: `samples/lml_listbuilder_mesa4core_sample.json`

**CuÃ¡ndo usar**:
- Antes de diseÃ±ar schema de nueva colecciÃ³n
- Para entender estructura de documentos
- Para identificar patrones de anidamiento

#### analyze_listbuilder.py

**PropÃ³sito**: AnÃ¡lisis estadÃ­stico de estructura JSON.

**Output ejemplo**:
```
CAMPOS DE PRIMER NIVEL:
  _id                              200/200 (100%)
  alias                            200/200 (100%)
  fields                           198/200 ( 99%)
  customerId                       200/200 (100%)
  
ARRAYS (cardinalidad):
  fields: min=0, max=15, avg=8.5
  items: min=0, max=5, avg=2.1
```

**CuÃ¡ndo usar**:
- Identificar campos opcionales vs obligatorios
- Decidir normalizaciÃ³n de arrays
- Estimar volumetrÃ­a de tablas relacionadas

### Interfaz BaseMigrator

**Archivo**: `migrators/base.py`

**PatrÃ³n de diseÃ±o**: Strategy Pattern
- `mongomigra.py` = Context (orquestador)
- `BaseMigrator` = Strategy (interfaz)
- `LmlProcessesMigrator` = Concrete Strategy

**MÃ©todos abstractos obligatorios**:

```python
class BaseMigrator(ABC):
    
    @abstractmethod
    def extract_shared_entities(self, doc, cursor, caches):
        """
        Procesa entidades compartidas (public.*).
        
        Responsabilidades:
        1. Extraer users, customers, areas, etc. del doc
        2. Insertar en public.* con ON CONFLICT DO NOTHING
        3. Usar caches para evitar procesamiento redundante
        4. Retornar IDs para usar en FKs
        
        Returns:
            {'customer_id': str, 'created_by_user_id': str, ...}
        """
    
    @abstractmethod
    def extract_data(self, doc, shared_entities):
        """
        Extrae datos especÃ­ficos de colecciÃ³n.
        
        Returns:
            {
                'main': tuple,          # Registro principal
                'related': {            # Tablas relacionadas
                    'movements': [tuple, tuple, ...],
                    'documents': [tuple, ...]
                }
            }
        """
    
    @abstractmethod
    def insert_batches(self, batches, cursor):
        """
        Inserta batches acumulados en PostgreSQL.
        
        Debe ejecutar executemany() para cada tipo de registro.
        """
    
    @abstractmethod
    def initialize_batches(self):
        """Retorna estructura vacÃ­a para acumular batches."""
    
    @abstractmethod
    def get_primary_key_from_doc(self, doc):
        """Extrae PK value desde documento MongoDB."""
```

### PatrÃ³n de ImplementaciÃ³n

**Template para agregar nuevo migrador**:

```python
# migrators/mi_coleccion.py

from .base import BaseMigrator
import config

class MiColeccionMigrator(BaseMigrator):
    """
    Migrador para mi_coleccion_mesa4core.
    
    Tablas destino:
    - {schema}.main: ...
    - {schema}.items: ...
    """
    
    def __init__(self, schema='mi_coleccion'):
        super().__init__(schema)
    
    # ===== MÃ‰TODOS PÃšBLICOS (INTERFAZ) =====
    
    def extract_shared_entities(self, doc, cursor, caches):
        # 1. Extraer customer_id
        customer_id = doc.get('customerId')
        if customer_id and customer_id not in caches['customers']:
            cursor.execute(
                "INSERT INTO public.customers (id) VALUES (%s) ON CONFLICT DO NOTHING",
                (customer_id,)
            )
            caches['customers'].add(customer_id)
        
        # 2. Extraer usuario creador si existe
        created_by_user_id = None
        if doc.get('createdBy'):
            created_by_user_id = self._process_user(
                doc['createdBy'], cursor, caches
            )
        
        return {
            'customer_id': customer_id,
            'created_by_user_id': created_by_user_id
        }
    
    def extract_data(self, doc, shared_entities):
        pk = self.get_primary_key_from_doc(doc)
        
        return {
            'main': self._extract_main(doc, shared_entities),
            'related': {
                'items': self._extract_items(doc, pk)
            }
        }
    
    def insert_batches(self, batches, cursor):
        if batches['main']:
            cursor.executemany(
                f"INSERT INTO {self.schema}.main (...) VALUES (...)",
                batches['main']
            )
        
        if batches['related']['items']:
            cursor.executemany(
                f"INSERT INTO {self.schema}.items (...) VALUES (...)",
                batches['related']['items']
            )
    
    def initialize_batches(self):
        return {
            'main': [],
            'related': {'items': []}
        }
    
    def get_primary_key_from_doc(self, doc):
        return str(doc['_id'])
    
    # ===== MÃ‰TODOS PRIVADOS (IMPLEMENTACIÃ“N) =====
    
    def _extract_main(self, doc, shared_entities):
        # LÃ³gica especÃ­fica...
        pass
    
    def _extract_items(self, doc, pk):
        # LÃ³gica especÃ­fica...
        pass
```

---

## Convenciones

### Nomenclatura

**Reglas de Mapeo MongoDB â†’ PostgreSQL**:

| Concepto | MongoDB | PostgreSQL | Ejemplo |
|----------|---------|------------|---------|
| ColecciÃ³n | `lml_processes_mesa4core` | Schema: `lml_processes` | `lml_processes.main` |
| Documento `_id` | `ObjectId("...")` | `process_id VARCHAR(255)` | Semantic name! |
| Campo anidado | `createdBy.user.id` | `created_by_user_id` | Snake_case |
| Array pequeÃ±o | `items: [...]` | `items JSONB` | Si <10 items |
| Array grande | `movements: [...]` | Tabla `movements` | Si >10 items |
| Timestamp | `ISODate("...")` | `TIMESTAMP` | Ver conversiÃ³n |

**Clases y MÃ©todos**:
```python
# Clases: PascalCase con sufijo "Migrator"
class LmlProcessesMigrator(BaseMigrator):
    pass

# MÃ©todos pÃºblicos: snake_case descriptivo
def extract_shared_entities(self, doc, cursor, caches):
    pass

# MÃ©todos privados: snake_case con prefijo "_"
def _extract_user_data(self, user_obj, cursor, caches):
    pass

# Variables: snake_case
process_id = doc.get('_id')
created_by_user_id = shared['created_by_user_id']
```

### Manejo de Timestamps

**Problema**: MongoDB almacena fechas en mÃºltiples formatos.

**ConversiÃ³n estandarizada**:

```python
def parse_mongo_timestamp(value):
    """
    Parsea timestamps de MongoDB a datetime de Python.
    
    Formatos soportados:
    1. Extended JSON: {'$date': '2025-01-15T10:30:00.000Z'}
    2. ISO8601 String: '2025-01-15T10:30:00.000Z'
    3. ISO8601 sin ms: '2025-01-15T10:30:00Z'
    4. Epoch millis: 1705318200000
    """
    if not value:
        return None
    
    # Caso 1: Extended JSON
    if isinstance(value, dict) and '$date' in value:
        value = value['$date']
    
    # Caso 2 y 3: String ISO8601
    if isinstance(value, str):
        try:
            if '.' in value:
                return datetime.strptime(value, "%Y-%m-%dT%H:%M:%S.%fZ")
            else:
                return datetime.strptime(value, "%Y-%m-%dT%H:%M:%SZ")
        except ValueError:
            return None
    
    # Caso 4: Epoch milliseconds
    if isinstance(value, int):
        return datetime.fromtimestamp(value / 1000, tz=timezone.utc)
    
    return None
```

**Uso en migrador**:
```python
def _extract_main_record(self, doc, shared_entities):
    created_at = parse_mongo_timestamp(doc.get('createdAt'))
    updated_at = parse_mongo_timestamp(doc.get('updatedAt'))
    
    return (
        process_id,
        ...,
        created_at,  # Python datetime â†’ PostgreSQL TIMESTAMP
        updated_at
    )
```

### Caching de Entidades Compartidas

**Problema**: Sin cachÃ©, cada documento procesa los mismos usuarios repetidamente.

**Impacto medido**:
- Sin cachÃ©: ~400 docs/min (5 queries por doc)
- Con cachÃ©: ~2,000 docs/min (0.1 queries por doc en promedio)

**ImplementaciÃ³n**:

```python
# Inicializar caches antes del loop
caches = {
    'users': set(),
    'customers': set(),
    'areas': set(),
    'subareas': set(),
    'roles': set(),
    'groups': set()
}

# Usar en extract_shared_entities
def extract_shared_entities(self, doc, cursor, caches):
    user_id = doc['createdBy']['user']['id']
    
    # âœ… Check cachÃ© primero (O(1) con set)
    if user_id in caches['users']:
        return user_id  # Skip DB operation
    
    # âš ï¸ Solo si NO estÃ¡ en cachÃ©: INSERT
    cursor.execute(
        "INSERT INTO public.users (...) VALUES (...) ON CONFLICT DO NOTHING",
        (user_id, ...)
    )
    
    # âœ… Agregar a cachÃ© para prÃ³ximas iteraciones
    caches['users'].add(user_id)
    
    return user_id
```

**Â¿Por quÃ© `set()` y no `list()` o `dict()`?**
- `set()`: O(1) para lookup con `in`
- `list()`: O(n) para lookup (lento con miles de usuarios)
- `dict()`: O(1) pero ocupa mÃ¡s memoria (no necesitamos valores)

---

## Workflow de AnÃ¡lisis

### Proceso Completo de AnÃ¡lisis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               WORKFLOW: AGREGAR NUEVA COLECCIÃ“N                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FASE 1: DESCUBRIMIENTO (15-20 min)
  â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ python export_sample.py <col> 200   â”‚  # Exportar muestra
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Abrir samples/<col>_sample.json     â”‚  # InspecciÃ³n manual
  â”‚                                     â”‚
  â”‚ Buscar:                             â”‚
  â”‚ - Campos de primer nivel            â”‚
  â”‚ - Arrays anidados                   â”‚
  â”‚ - Referencias a usuarios/customers  â”‚
  â”‚ - Timestamps                        â”‚
  â”‚ - Estructura de IDs                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
FASE 2: DISEÃ‘O (30-40 min)
  â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Decisiones de normalizaciÃ³n:                 â”‚
  â”‚                                              â”‚
  â”‚ Para cada array:                             â”‚
  â”‚   Â¿Cardinalidad alta (>50)? â†’ Tabla         â”‚
  â”‚   Â¿Tiene FK? â†’ Tabla                         â”‚
  â”‚   Â¿Se consulta en WHERE? â†’ Tabla            â”‚
  â”‚   Sino â†’ JSONB                               â”‚
  â”‚                                              â”‚
  â”‚ Para cada campo:                             â”‚
  â”‚   Â¿Es user/customer? â†’ FK a public.*        â”‚
  â”‚   Â¿Es timestamp? â†’ TIMESTAMP                â”‚
  â”‚   Â¿Estructura variable? â†’ JSONB             â”‚
  â”‚   Sino â†’ Columna simple                      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ DiseÃ±ar schema SQL:                          â”‚
  â”‚                                              â”‚
  â”‚ 1. Tabla main con PK semÃ¡ntica              â”‚
  â”‚ 2. Tablas relacionadas (1:N)                â”‚
  â”‚ 3. Foreign Keys a public.*                  â”‚
  â”‚ 4. Ãndices en columnas de bÃºsqueda          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
FASE 3: IMPLEMENTACIÃ“N (60-90 min)
  â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 1. dbsetup.py                                â”‚
  â”‚    Agregar creaciÃ³n de schema y tablas      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 2. config.py                                 â”‚
  â”‚    Agregar entrada en COLLECTIONS            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 3. migrators/mi_coleccion.py                 â”‚
  â”‚    Implementar BaseMigrator                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
FASE 4: VALIDACIÃ“N (15-20 min)
  â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ python dbsetup.py              # Crear tablasâ”‚
  â”‚ python mongomigra.py           # Migrar      â”‚
  â”‚                                              â”‚
  â”‚ Verificar:                                   â”‚
  â”‚ - Conteo de registros                        â”‚
  â”‚ - Foreign keys vÃ¡lidas                       â”‚
  â”‚ - Queries de prueba                          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ejemplo Real: lml_processes

**1. Documento MongoDB (simplificado)**:
```json
{
  "_id": "507f1f77bcf86cd799439011",
  "processNumber": "TR-2024-001",
  "customerId": "CUST001",
  "createdBy": {
    "user": {
      "id": "USR001",
      "email": "juan@ejemplo.com",
      "area": {"id": "AREA01", "name": "Operaciones"}
    }
  },
  "movements": [
    {"at": "2024-01-15T10:00:00Z", "to": "AprobaciÃ³n"},
    {"at": "2024-01-16T14:30:00Z", "to": "Finalizado"}
  ],
  "initiatorFields": {
    "monto": {"id": "FLD001", "name": "Monto Total"}
  }
}
```

**2. Decisiones de NormalizaciÃ³n**:

| Elemento | DecisiÃ³n | RazÃ³n |
|----------|----------|-------|
| `_id` | â†’ `process_id VARCHAR(255) PK` | Semantic naming |
| `customerId` | â†’ FK a `public.customers` | Entidad compartida |
| `createdBy.user` | â†’ FK a `public.users` | Entidad compartida + normalizar area |
| `movements[]` | â†’ Tabla `lml_processes.movements` | Array grande, se consulta |
| `initiatorFields{}` | â†’ Tabla `lml_processes.initiator_fields` | Dict dinÃ¡mico, normalizable |

**3. Schema SQL Resultante**:
```sql
-- Tabla principal
CREATE TABLE lml_processes.main (
    process_id VARCHAR(255) PRIMARY KEY,
    process_number VARCHAR(255),
    customer_id VARCHAR(255) REFERENCES public.customers(id),
    created_by_user_id VARCHAR(255) REFERENCES public.users(id),
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);

-- Tabla relacionada 1:N
CREATE TABLE lml_processes.movements (
    id SERIAL PRIMARY KEY,
    process_id VARCHAR(255) REFERENCES lml_processes.main(process_id),
    movement_at TIMESTAMP,
    destination_type VARCHAR(50)
);

-- Campos dinÃ¡micos
CREATE TABLE lml_processes.initiator_fields (
    id SERIAL PRIMARY KEY,
    process_id VARCHAR(255) REFERENCES lml_processes.main(process_id),
    field_key VARCHAR(255),
    field_id VARCHAR(255),
    field_name VARCHAR(255)
);
```

### Patrones Comunes de IdentificaciÃ³n

**Tabla de referencia rÃ¡pida**:

| PatrÃ³n en MongoDB | AcciÃ³n | Destino PostgreSQL |
|-------------------|--------|--------------------|
| `{user: {id, email, ...}}` | Normalizar usuario completo | FK a `public.users` |
| `customerId: "..."` | FK simple | FK a `public.customers` |
| `movements: [{...}, {...}]` | Array grande | Tabla relacionada |
| `config: {key: val, ...}` | Estructura variable | JSONB column |
| `createdAt: ISODate(...)` | Timestamp | `TIMESTAMP` column |
| `deleted: true` | Boolean | `BOOLEAN` column |
| `tags: ["tag1", "tag2"]` | Array simple | `TEXT[]` o tabla |

---

## Agregar Nueva ColecciÃ³n

### Checklist Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           CHECKLIST: AGREGAR COLECCIÃ“N NUEVA                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â–¡ PASO 1: Exportar y analizar
  â–¡ python export_sample.py <collection_name> 200
  â–¡ Revisar samples/<collection>_sample.json
  â–¡ Identificar:
    â–¡ Entidades compartidas (users, customers, etc.)
    â–¡ Arrays que requieren normalizaciÃ³n
    â–¡ Campos JSONB vs columnas simples
    â–¡ Primary key semÃ¡ntica

â–¡ PASO 2: DiseÃ±ar schema PostgreSQL
  â–¡ Definir nombre de schema (ej: lml_nueva_coleccion)
  â–¡ DiseÃ±ar tabla main con PK semÃ¡ntica
  â–¡ DiseÃ±ar tablas relacionadas (1:N)
  â–¡ Definir Foreign Keys a public.*
  â–¡ Identificar columnas para Ã­ndices

â–¡ PASO 3: Actualizar config.py
  â–¡ Agregar entrada en COLLECTIONS:
    ```python
    "mi_coleccion_mesa4core": {
        "postgres_schema": "mi_coleccion",
        "primary_key": "mi_id",  # Semantic!
        "shared_entities": ["users", "customers"],
        "description": "..."
    }
    ```

â–¡ PASO 4: Extender dbsetup.py
  â–¡ Agregar funciÃ³n setup_<mi_coleccion>_schema()
  â–¡ Incluir:
    â–¡ CREATE SCHEMA IF NOT EXISTS
    â–¡ CREATE TABLE para main
    â–¡ CREATE TABLE para cada relacionada
    â–¡ Foreign Keys apropiadas
  â–¡ Llamar funciÃ³n desde main()

â–¡ PASO 5: Implementar migrador
  â–¡ Crear migrators/mi_coleccion.py
  â–¡ Heredar de BaseMigrator
  â–¡ Implementar 5 mÃ©todos abstractos:
    â–¡ extract_shared_entities()
    â–¡ extract_data()
    â–¡ insert_batches()
    â–¡ initialize_batches()
    â–¡ get_primary_key_from_doc()
  â–¡ MÃ©todos privados de ayuda segÃºn necesidad

â–¡ PASO 6: Testing inicial
  â–¡ python dbsetup.py  # Crear tablas
  â–¡ Verificar en psql que schemas existen
  â–¡ python mongomigra.py  # Probar con 10-100 docs
  â–¡ Revisar logs de errores

â–¡ PASO 7: ValidaciÃ³n de integridad
  â–¡ Comparar conteos:
    â–¡ MongoDB: db.<collection>.countDocuments({})
    â–¡ PostgreSQL: SELECT COUNT(*) FROM <schema>.main
  â–¡ Verificar Foreign Keys:
    â–¡ No deben haber valores NULL en FKs obligatorias
    â–¡ Todas las FKs deben tener registro padre
  â–¡ Queries de prueba:
    â–¡ Joins entre main y relacionadas
    â–¡ Joins con public.users, public.customers

â–¡ PASO 8: OptimizaciÃ³n
  â–¡ Medir tiempo de migraciÃ³n completa
  â–¡ Ajustar BATCH_SIZE si es necesario
  â–¡ Agregar Ã­ndices para queries lentas
  â–¡ Documentar en este archivo
```

### CÃ³digo Ejemplo para Cada Paso

**PASO 3: config.py**
```python
COLLECTIONS = {
    # ... colecciones existentes ...
    
    "lml_nueva_coleccion_mesa4core": {
        "postgres_schema": "lml_nueva_coleccion",
        "primary_key": "nueva_id",  # âš ï¸ Semantic, not "mongo_id"!
        "shared_entities": ["users", "customers", "areas"],
        "description": "DescripciÃ³n breve de quÃ© contiene"
    }
}
```

**PASO 4: dbsetup.py**
```python
def setup_lml_nueva_coleccion_schema(cursor, conn):
    """Crea schema y tablas para lml_nueva_coleccion."""
    print("\nğŸ”§ Configurando schema 'lml_nueva_coleccion'...")
    
    # Crear schema
    cursor.execute("CREATE SCHEMA IF NOT EXISTS lml_nueva_coleccion;")
    
    # Tabla main
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS lml_nueva_coleccion.main (
            nueva_id VARCHAR(255) PRIMARY KEY,  -- Semantic PK!
            campo1 VARCHAR(255),
            customer_id VARCHAR(255) REFERENCES public.customers(id),
            created_by_user_id VARCHAR(255) REFERENCES public.users(id),
            created_at TIMESTAMP,
            updated_at TIMESTAMP
        );
    """)
    
    # Tabla relacionada ejemplo
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS lml_nueva_coleccion.items (
            id SERIAL PRIMARY KEY,
            nueva_id VARCHAR(255) REFERENCES lml_nueva_coleccion.main(nueva_id),
            item_name VARCHAR(255),
            item_order INTEGER
        );
    """)
    
    conn.commit()
    print("âœ… Schema 'lml_nueva_coleccion' configurado")

# En main(), agregar:
def main():
    # ... cÃ³digo existente ...
    setup_lml_nueva_coleccion_schema(cursor, conn)
    # ...
```

**PASO 5: migrators/mi_coleccion.py** (ver template completo en secciÃ³n "Estructura de CÃ³digo")

**PASO 7: ValidaciÃ³n**
```bash
# En MongoDB
mongo --host <host> --eval "db.lml_nueva_coleccion_mesa4core.countDocuments({})"

# En PostgreSQL
psql -U <user> -d mesamongo -c "SELECT COUNT(*) FROM lml_nueva_coleccion.main;"

# Verificar Foreign Keys
psql -U <user> -d mesamongo -c "
SELECT COUNT(*) 
FROM lml_nueva_coleccion.main m
LEFT JOIN public.users u ON m.created_by_user_id = u.id
WHERE m.created_by_user_id IS NOT NULL AND u.id IS NULL;
"
# Output esperado: 0 (no debe haber FKs huÃ©rfanas)
```

---

## Testing

### EjecuciÃ³n de Tests

Actualmente **no hay test suite unitaria tradicional**. El testing se basa en:

1. **ValidaciÃ³n de Arquitectura**: Verificar que la migraciÃ³n preserva estructura
2. **Tests de Integridad**: Queries SQL que validan constraints
3. **Tests Manuales**: ComparaciÃ³n MongoDB vs PostgreSQL

**Comandos de validaciÃ³n**:

```bash
# 1. MigraciÃ³n completa de colecciÃ³n
python mongomigra.py
# â†’ Seleccionar colecciÃ³n del menÃº
# â†’ Observar logs sin errores
# â†’ Verificar tiempo de ejecuciÃ³n

# 2. Verificar conteos
psql -U <user> -d mesamongo << EOF
SELECT 'lml_processes.main' as tabla, COUNT(*) FROM lml_processes.main
UNION ALL
SELECT 'lml_processes.movements', COUNT(*) FROM lml_processes.movements
UNION ALL
SELECT 'public.users', COUNT(*) FROM public.users;
EOF

# 3. Verificar integridad referencial
psql -U <user> -d mesamongo << EOF
-- Procesos sin usuario creador vÃ¡lido
SELECT COUNT(*)
FROM lml_processes.main m
LEFT JOIN public.users u ON m.created_by_user_id = u.id
WHERE m.created_by_user_id IS NOT NULL AND u.id IS NULL;
-- Output esperado: 0

-- Movimientos sin proceso padre
SELECT COUNT(*)
FROM lml_processes.movements mov
LEFT JOIN lml_processes.main m ON mov.process_id = m.process_id
WHERE m.process_id IS NULL;
-- Output esperado: 0
EOF
```

### Cobertura de ValidaciÃ³n

| Aspecto | MÃ©todo de Testing | Criterio de Ã‰xito |
|---------|-------------------|-------------------|
| Conteo de registros | Comparar `COUNT(*)` Mongo vs PG | Diferencia < 1% |
| Foreign Keys | Query con LEFT JOIN buscando NULLs | 0 registros huÃ©rfanos |
| Timestamps | Query con `created_at IS NULL` | 0 NULLs en campos obligatorios |
| Unicidad de PKs | Query con `GROUP BY HAVING COUNT(*) > 1` | 0 duplicados |
| Performance | Medir tiempo total de migraciÃ³n | Dentro de Â±20% de baseline |

**Queries de validaciÃ³n estÃ¡ndar**:

```sql
-- Test 1: Contar duplicados en PK
SELECT process_id, COUNT(*) as cnt
FROM lml_processes.main
GROUP BY process_id
HAVING COUNT(*) > 1;
-- Output esperado: 0 rows

-- Test 2: Verificar que no hay FKs NULL cuando deberÃ­an existir
SELECT COUNT(*)
FROM lml_processes.main
WHERE customer_id IS NULL;
-- Output: Depende del negocio, revisar si es esperado

-- Test 3: Verificar rangos de fechas
SELECT MIN(created_at), MAX(created_at)
FROM lml_processes.main;
-- Output: Fechas deben ser razonables (no 1970 ni 2050)

-- Test 4: Verificar consistencia de relaciones 1:N
SELECT 
    m.process_id,
    COUNT(mov.id) as num_movements
FROM lml_processes.main m
LEFT JOIN lml_processes.movements mov ON m.process_id = mov.process_id
GROUP BY m.process_id
ORDER BY num_movements DESC
LIMIT 10;
-- Revisar que los procesos con muchos movimientos sean lÃ³gicos
```

### FilosofÃ­a de Testing

**Por quÃ© NO tests unitarios tradicionales**:

1. **Naturaleza del proyecto**: Es una migraciÃ³n de datos, no lÃ³gica de negocio
2. **Datos reales son el test**: Los datos de producciÃ³n revelan casos edge que unit tests no capturan
3. **ValidaciÃ³n post-migraciÃ³n**: Es mÃ¡s importante verificar el resultado final que cada funciÃ³n individual

**Lo que SÃ hacemos**:

- âœ… ValidaciÃ³n de arquitectura (schemas, tablas, FKs correctas)
- âœ… Tests de integridad referencial
- âœ… ComparaciÃ³n de volumetrÃ­a
- âœ… Queries de smoke test

**Lo que NO hacemos (y por quÃ© estÃ¡ bien)**:

- ğŸš« Unit tests de cada funciÃ³n `_extract_*()` â†’ Los datos reales son suficiente test
- ğŸš« Mocks de MongoDB/PostgreSQL â†’ Queremos probar contra las DBs reales
- ğŸš« Coverage al 100% â†’ No es el objetivo en este tipo de proyecto

---

## ConfiguraciÃ³n de Performance

### BATCH_SIZE = 2000

**Valor actual**: `config.py` define `BATCH_SIZE = 2000`

**JustificaciÃ³n tÃ©cnica**:

```
BATCH_SIZE = NÃºmero de documentos procesados antes de hacer INSERT masivo

Trade-off fundamental:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  MÃ¡s grande (5000+)          MÃ¡s pequeÃ±o (500-)            â”‚
â”‚  âœ… Menos round-trips DB      âœ… Menos memoria RAM          â”‚
â”‚  âœ… MÃ¡s rÃ¡pido               âœ… MÃ¡s seguro ante errores     â”‚
â”‚  ğŸš« MÃ¡s memoria              ğŸš« MÃ¡s round-trips             â”‚
â”‚  ğŸš« Riesgo de OOM            ğŸš« MÃ¡s lento                   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mediciones reales** (lml_processes, ~129k docs):

| BATCH_SIZE | Tiempo Total | Docs/seg | Memoria Pico | Observaciones |
|------------|--------------|----------|--------------|---------------|
| 500 | ~25 min | ~86 | 150 MB | Muchos commits |
| 1000 | ~22 min | ~98 | 200 MB | Balanceado |
| **2000** | **~20 min** | **~107** | **280 MB** | **âœ… Elegido** |
| 5000 | ~18 min | ~119 | 600 MB | Cerca del lÃ­mite |

**Por quÃ© 2000**:
1. Performance cercana al Ã³ptimo (solo 10% mÃ¡s lento que 5000)
2. Memoria segura (280 MB << 2 GB disponible)
3. Margen para colecciones mÃ¡s grandes en el futuro

### Tabla de Recomendaciones

| SituaciÃ³n | BATCH_SIZE Recomendado | RazÃ³n |
|-----------|------------------------|-------|
| Documentos pequeÃ±os (<5 KB) | 2000-5000 | MÃ¡s docs caben en memoria |
| Documentos grandes (>50 KB) | 500-1000 | Evitar OOM |
| ColecciÃ³n gigante (>1M docs) | 1000-2000 | Balance tiempo/estabilidad |
| Testing/debugging | 100-500 | Feedback rÃ¡pido |
| MÃ¡quina con poca RAM | 500-1000 | PrevenciÃ³n |

### Tuning EmpÃ­rico

**Proceso para ajustar BATCH_SIZE**:

```python
# 1. Agregar logging de tiempo
import time

start = time.time()
for i in range(0, len(docs), BATCH_SIZE):
    # ... procesar batch ...
    elapsed = time.time() - start
    docs_per_sec = (i + BATCH_SIZE) / elapsed
    print(f"Docs procesados: {i}/{total} ({docs_per_sec:.1f} docs/seg)")

# 2. Experimentar con valores
# Probar: 500, 1000, 2000, 5000
# Registrar: tiempo, memoria (usar htop/task manager)

# 3. Elegir el valor donde:
# - Tiempo es < 110% del Ã³ptimo
# - Memoria es < 50% del disponible
# - Sin errores de OOM
```

**Concepto clave**: No siempre el mÃ¡s rÃ¡pido es el mejor. Priorizar:
1. **Estabilidad** (no fallar por OOM)
2. **Tiempo razonable** (dentro de 20% del Ã³ptimo)
3. **Margen de seguridad** (para documentos mÃ¡s grandes inesperados)

---

## Troubleshooting

### Error: duplicate key value violates unique constraint

**Error completo**:
```
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "users_pkey"
DETAIL: Key (id)=(USR001) already exists.
```

**Causa**:
- Intentando insertar un usuario que ya existe en `public.users`
- Olvidaste agregar `ON CONFLICT DO NOTHING`

**SoluciÃ³n**:
```python
# âŒ Incorrecto
cursor.execute(
    "INSERT INTO public.users (id, email) VALUES (%s, %s)",
    (user_id, email)
)

# âœ… Correcto
cursor.execute(
    "INSERT INTO public.users (id, email) VALUES (%s, %s) ON CONFLICT (id) DO NOTHING",
    (user_id, email)
)
```

**PrevenciÃ³n**:
- Todas las inserts en `public.*` deben tener `ON CONFLICT`
- Usar cachÃ© para evitar INSERTs redundantes

---

### Error: relation does not exist

**Error completo**:
```
psycopg2.errors.UndefinedTable: relation "lml_nueva_coleccion.main" does not exist
```

**Causa**:
- No ejecutaste `python dbsetup.py` antes de migrar
- Typo en el nombre del schema o tabla

**SoluciÃ³n**:
```bash
# 1. Verificar que el schema existe
psql -U <user> -d mesamongo -c "\dn"

# 2. Si no existe, ejecutar setup
python dbsetup.py

# 3. Verificar que las tablas se crearon
psql -U <user> -d mesamongo -c "\dt lml_nueva_coleccion.*"
```

**PrevenciÃ³n**:
- Siempre ejecutar `dbsetup.py` primero
- Agregar check en `mongomigra.py`:
  ```python
  def verify_schema_exists(cursor, schema_name):
      cursor.execute(
          "SELECT schema_name FROM information_schema.schemata WHERE schema_name = %s",
          (schema_name,)
      )
      if not cursor.fetchone():
          print(f"âŒ Schema '{schema_name}' no existe. Ejecuta: python dbsetup.py")
          sys.exit(1)
  ```

---

### Error: 'NoneType' object has no attribute

**Error completo**:
```
AttributeError: 'NoneType' object has no attribute 'get'
Traceback:
  user_id = doc['createdBy']['user'].get('id')
```

**Causa**:
- Campo esperado no existe en el documento
- Anidamiento profundo sin checks de None

**SoluciÃ³n**:
```python
# âŒ Asume estructura siempre presente
user_id = doc['createdBy']['user'].get('id')

# âœ… Checks defensivos
created_by = doc.get('createdBy')
if not created_by:
    return None

user = created_by.get('user')
if not user:
    return None

user_id = user.get('id')
```

**PatrÃ³n recomendado**:
```python
def safe_get_nested(doc, *keys, default=None):
    """
    Obtiene valor anidado de forma segura.
    
    Ejemplo:
        safe_get_nested(doc, 'createdBy', 'user', 'id')
        # Equivale a: doc.get('createdBy', {}).get('user', {}).get('id')
    """
    result = doc
    for key in keys:
        if not isinstance(result, dict):
            return default
        result = result.get(key)
        if result is None:
            return default
    return result

# Uso
user_id = safe_get_nested(doc, 'createdBy', 'user', 'id')
```

---

### Performance lenta: Solo 50-100 docs/seg

**SÃ­ntomas**:
- MigraciÃ³n tarda horas en lugar de minutos
- Cada documento toma >100ms

**DiagnÃ³stico**:
```python
import time

# Agregar timing a cada operaciÃ³n
t1 = time.time()
shared = migrator.extract_shared_entities(doc, cursor, caches)
t2 = time.time()
data = migrator.extract_data(doc, shared)
t3 = time.time()

print(f"extract_shared_entities: {(t2-t1)*1000:.1f}ms")
print(f"extract_data: {(t3-t2)*1000:.1f}ms")
```

**Causas comunes**:

1. **Sin cachÃ© de entidades**
   ```python
   # âŒ Problema: Procesa mismo usuario 1000 veces
   for doc in docs:
       process_user(doc['createdBy']['user'])  # INSERT cada vez
   
   # âœ… SoluciÃ³n: Usar cachÃ©
   for doc in docs:
       user_id = doc['createdBy']['user']['id']
       if user_id not in caches['users']:
           process_user(...)
           caches['users'].add(user_id)
   ```

2. **BATCH_SIZE muy pequeÃ±o**
   ```python
   # âŒ BATCH_SIZE = 10  â†’ 12,900 commits para 129k docs
   # âœ… BATCH_SIZE = 2000 â†’ 65 commits
   ```

3. **Ãndices faltantes en PostgreSQL**
   ```sql
   -- Agregar Ã­ndices en columnas de bÃºsqueda frecuente
   CREATE INDEX idx_users_email ON public.users(email);
   CREATE INDEX idx_main_customer ON lml_processes.main(customer_id);
   ```

4. **Commits muy frecuentes**
   ```python
   # âŒ Commit despuÃ©s de cada INSERT
   cursor.execute(...)
   conn.commit()  # LentÃ­simo!
   
   # âœ… Commit cada batch
   if count % BATCH_SIZE == 0:
       conn.commit()
   ```

**Optimizaciones medidas**:

| OptimizaciÃ³n | Antes | DespuÃ©s | Mejora |
|--------------|-------|---------|--------|
| Agregar cachÃ© | 400 docs/min | 2000 docs/min | 5x |
| Aumentar batch 500â†’2000 | 22 min | 20 min | 10% |
| Ãndices en FKs | 20 min | 18 min | 10% |

---

### Foreign Key Violation

**Error completo**:
```
psycopg2.errors.ForeignKeyViolation: insert or update on table "main" violates foreign key constraint "main_created_by_user_id_fkey"
DETAIL: Key (created_by_user_id)=(USR999) is not present in table "users".
```

**Causa**:
- Intentando insertar FK antes que el registro padre exista
- Usuario no fue procesado en `extract_shared_entities()`

**SoluciÃ³n**:
```python
def extract_shared_entities(self, doc, cursor, caches):
    # âœ… SIEMPRE procesar usuarios ANTES de retornar IDs
    created_by_user_id = None
    if doc.get('createdBy'):
        created_by_user_id = self._process_user(
            doc['createdBy']['user'], 
            cursor, 
            caches
        )
        # âš ï¸ Verificar que el usuario se insertÃ³
        if created_by_user_id:
            cursor.execute(
                "SELECT id FROM public.users WHERE id = %s",
                (created_by_user_id,)
            )
            if not cursor.fetchone():
                print(f"âš ï¸ Usuario {created_by_user_id} no existe despuÃ©s de procesar")
                created_by_user_id = None
    
    return {'created_by_user_id': created_by_user_id}
```

**Debugging**:
```sql
-- Encontrar registros con FKs invÃ¡lidas ANTES de la migraciÃ³n
SELECT m.process_id, m.created_by_user_id
FROM lml_processes.main m
LEFT JOIN public.users u ON m.created_by_user_id = u.id
WHERE m.created_by_user_id IS NOT NULL AND u.id IS NULL
LIMIT 10;
```

---

## MÃ©tricas y Recursos

### Performance Actual

**Tabla de mÃ©tricas medidas**:

| ColecciÃ³n | Documentos | Tiempo | Docs/seg | Memoria | Complejidad |
|-----------|------------|--------|----------|---------|-------------|
| lml_processes | ~129,000 | ~20 min | ~107 | 280 MB | Alta (5 tablas) |
| lml_listbuilder | ~200 | <1 min | N/A | <50 MB | Alta (9 tablas) |

**Desglose lml_processes**:

| Fase | Tiempo | % Total | DescripciÃ³n |
|------|--------|---------|-------------|
| ConexiÃ³n DB | ~5 seg | <1% | Conectar Mongo + PostgreSQL |
| Procesamiento | ~19 min | 95% | Loop principal de migraciÃ³n |
| Final commit | ~30 seg | 4% | Ãšltimo batch + Ã­ndices |

### ProyecciÃ³n para EjecuciÃ³n Completa

Asumiendo 8 colecciones total con volumetrÃ­as variadas:

| ColecciÃ³n (estimado) | Docs | Tiempo Est. | Estado |
|----------------------|------|-------------|--------|
| lml_processes | 129k | 20 min | âœ… Migrado |
| lml_listbuilder | 200 | <1 min | âœ… Migrado |
| lml_clients | ~50k | ~8 min | ğŸ”§ Pendiente |
| lml_providers | ~30k | ~5 min | ğŸ”§ Pendiente |
| lml_products | ~100k | ~15 min | ğŸ”§ Pendiente |
| lml_invoices | ~200k | ~30 min | ğŸ”§ Pendiente |
| lml_reports | ~10k | ~2 min | ğŸ”§ Pendiente |
| lml_settings | ~500 | <1 min | ğŸ”§ Pendiente |
| **TOTAL** | **~520k** | **~81 min** | **2/8 done** |

**Nota**: Proyecciones basadas en ratio de ~107 docs/seg para colecciones complejas.

### ConfiguraciÃ³n Futura para n8n

**Objetivo**: SincronizaciÃ³n automÃ¡tica cada N horas/dÃ­as.

**Arquitectura propuesta**:
```
n8n Workflow:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Trigger: Cron (ej: cada 6 horas)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Execute: python mongomigra.py     â”‚
  â”‚  (con modo batch no-interactivo)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Parse output logs                 â”‚
  â”‚  - Documentos procesados           â”‚
  â”‚  - Tiempo total                    â”‚
  â”‚  - Errores si los hay              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Enviar notificaciÃ³n               â”‚
  â”‚  - Email/Slack con resultado       â”‚
  â”‚  - Alertas si hay errores          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Modificaciones requeridas en mongomigra.py**:
```python
# Agregar argumento CLI para modo batch
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('--collection', help='Nombre de colecciÃ³n a migrar')
parser.add_argument('--all', action='store_true', help='Migrar todas las colecciones')
parser.add_argument('--quiet', action='store_true', help='Modo silencioso')
args = parser.parse_args()

if args.all:
    for collection_name in config.COLLECTIONS.keys():
        migrate_collection(collection_name, quiet=args.quiet)
elif args.collection:
    migrate_collection(args.collection, quiet=args.quiet)
else:
    # Modo interactivo actual
    show_collection_menu()
```

### Historial de Versiones

| VersiÃ³n | Fecha | Cambios Principales |
|---------|-------|---------------------|
| v1.0 | 2025-10-30 | POC inicial: migraciÃ³n monolÃ­tica de lml_processes |
| v2.0 | 2025-11-05 | RefactorizaciÃ³n: nomenclatura semÃ¡ntica (process_id vs mongo_id) |
| v3.0 | 2025-11-15 | Arquitectura multi-colecciÃ³n: BaseMigrator + carga dinÃ¡mica |
| v3.1 | 2025-01-19 | Segunda colecciÃ³n (lml_listbuilder) + documentaciÃ³n completa |

### Recursos Adicionales

**DocumentaciÃ³n PostgreSQL**:
- Foreign Keys: https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-FK
- JSONB: https://www.postgresql.org/docs/current/datatype-json.html
- Batch INSERT: https://www.psycopg.org/docs/extras.html#fast-execution-helpers

**DocumentaciÃ³n MongoDB**:
- Extended JSON: https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/
- PyMongo Cursor: https://pymongo.readthedocs.io/en/stable/api/pymongo/cursor.html

**Convenciones y Patrones**:
- Strategy Pattern: https://refactoring.guru/design-patterns/strategy/python
- Repository Pattern: https://martinfowler.com/eaaCatalog/repository.html

**Herramientas Ãºtiles**:
- DBeaver: Cliente SQL multi-plataforma (Ãºtil para inspeccionar PostgreSQL)
- MongoDB Compass: GUI para explorar colecciones MongoDB
- pgAdmin: Cliente oficial de PostgreSQL

---

## ğŸ”§ Stack TecnolÃ³gico

### TecnologÃ­as Core
- **Python 3.12**: Lenguaje de programaciÃ³n principal
- **pymongo**: Driver y cliente de MongoDB
- **psycopg2**: Adaptador de PostgreSQL
- **python-dotenv**: GestiÃ³n de variables de entorno

### Sistemas de Base de Datos
- **MongoDB** (Origen): Base de datos NoSQL orientada a documentos
- **PostgreSQL** (Destino): Base de datos SQL relacional

## ğŸ“Š TransformaciÃ³n del Modelo de Datos

### Estructura MongoDB (Original)
Los documentos en la colecciÃ³n `lml_processes_mesa4core` contienen objetos profundamente anidados:

```javascript
{
  _id: ObjectId("..."),
  processNumber: "12345",
  customerId: "CUST001",
  createdBy: {
    user: {
      id: "USR001",
      email: "usuario@ejemplo.com",
      firstname: "Juan",
      lastname: "PÃ©rez",
      area: { id: "AREA01", name: "Operaciones" },
      subarea: { id: "SUB01", name: "LogÃ­stica" },
      role: { id: "ROLE01", name: "Gerente" },
      groups: [{ id: "GRP01", name: "Administradores" }]
    }
  },
  movements: [
    { at: ISODate("..."), id: "MOV001", to: "destino" }
  ],
  initiatorFields: {
    campo1: { id: "FLD01", name: "Campo Uno" }
  }
}
```

### Estructura PostgreSQL (Transformada)

#### Entidades Compartidas (schema public)
```sql
public.users (
  id VARCHAR(255) PRIMARY KEY,
  email VARCHAR(255) UNIQUE,
  firstname VARCHAR(255),
  lastname VARCHAR(255),
  area_id VARCHAR(255) â†’ public.areas(id),
  subarea_id VARCHAR(255) â†’ public.subareas(id),
  role_id VARCHAR(255) â†’ public.roles(id)
)

public.customers (
  id VARCHAR(255) PRIMARY KEY
)
```

#### EspecÃ­fico de ColecciÃ³n (schema lml_processes)
```sql
lml_processes.main (
  process_id VARCHAR(255) PRIMARY KEY,  -- Anteriormente mongo_id
  process_number VARCHAR(255),
  customer_id VARCHAR(255) â†’ public.customers(id),
  created_by_user_id VARCHAR(255) â†’ public.users(id),
  updated_by_user_id VARCHAR(255) â†’ public.users(id),
  ...
)

lml_processes.movements (
  id SERIAL PRIMARY KEY,
  process_id VARCHAR(255) â†’ lml_processes.main(process_id),  -- Anteriormente record_id
  movement_at TIMESTAMP,
  destination_id VARCHAR(255),
  destination_type VARCHAR(50)
)
```

### Convenciones de Nomenclatura Clave
Las mejoras recientes establecen patrones claros:

1. **Claves Primarias**: Usar nombres semÃ¡nticos (`process_id` no `mongo_id`)
2. **Claves ForÃ¡neas**: Coincidir con nombres de claves primarias referenciadas (`process_id` no `record_id`)
3. **Consistencia**: La misma entidad se referencia de la misma forma en todos lados

## ğŸ“œ Scripts Actuales

### `config.py` - GestiÃ³n de ConfiguraciÃ³n
Centraliza toda la configuraciÃ³n no sensible:

```python
# Detalles de conexiÃ³n MongoDB
MONGO_URI  # Construido desde variables de entorno
MONGO_DATABASE_NAME = "mesa4core"
MONGO_SOURCE_COLLECTION = "lml_processes_mesa4core"

# Detalles de conexiÃ³n PostgreSQL
POSTGRES_CONFIG = {
    'dbname': os.getenv('POSTGRES_DB'),  # "mesamongo"
    # ... otros parÃ¡metros de conexiÃ³n
}

# Mapeos de nombres de tablas
TABLE_NAMES = { ... }

# ConfiguraciÃ³n de migraciÃ³n
POC_SCHEMA_NAME = "lml_processes"
BATCH_SIZE = 500  # Registros por inserciÃ³n en lote
```

**DecisiÃ³n de DiseÃ±o**: Separar la configuraciÃ³n de la lÃ³gica permite:
- Ajustes fÃ¡ciles sin cambios de cÃ³digo
- Futura conversiÃ³n a archivos de configuraciÃ³n (JSON/YAML)
- DocumentaciÃ³n clara de los parÃ¡metros del sistema

### `mongomigra.py` - Motor de MigraciÃ³n
El script principal de migraciÃ³n implementa:

#### 1. GestiÃ³n de Conexiones
```python
def connect_to_mongo()
def connect_to_postgres()
```
Establecen conexiones con manejo de errores apropiado y configuraciÃ³n de timeouts.

#### 2. CreaciÃ³n de Schema
```python
def create_postgres_tables(pg_cursor, pg_conn)
```
Crea la estructura completa del schema hÃ­brido. Actualmente usa `DROP TABLE CASCADE` para migraciones de pizarra limpia.

**Importante**: Esto es aceptable para POC pero debe refactorizarse para producciÃ³n (ver Mejoras Futuras).

#### 3. Procesamiento de Entidades con CachÃ©
```python
def process_user_data(user_obj, pg_cursor, caches)
def process_customer_data(customer_id, pg_cursor, caches)
```

**El PatrÃ³n de CachÃ©**: OptimizaciÃ³n crÃ­tica de rendimiento
- **Problema**: Sin cachÃ©, cada documento procesa usuarios redundantemente
- **SoluciÃ³n**: `set()` en memoria rastrea entidades ya procesadas
- **Impacto**: Mejora de velocidad de ~5x (2,000 docs/min vs. 400 docs/min)

```python
caches = {
    'users': set(),
    'customers': set(),
    # ... otras entidades
}

# Ruta rÃ¡pida: bÃºsqueda O(1)
if user_id in caches['users']:
    return user_id  # Saltar operaciÃ³n de base de datos

# Ruta lenta: Insertar en base de datos
pg_cursor.execute("INSERT INTO public.users ...")
caches['users'].add(user_id)  # Recordar para la prÃ³xima vez
```

#### 4. MigraciÃ³n por Lotes
```python
def migrate_collection(mongo_db, pg_cursor, pg_conn)
```

**Estrategia de Procesamiento por Lotes**:
- Acumula registros en listas en memoria (ej., `main_batch`, `movements_batch`)
- Inserta en lotes de 500 usando `executemany()`
- Hace commit de cada lote a la base de datos

**Â¿Por quÃ© por Lotes?**
- `INSERT` Ãºnico: ~10-50ms por registro = 20 registros/segundo
- `INSERT` por lotes: ~100ms por 500 registros = 5,000 registros/segundo
- Overhead de red reducido en ~99%

```python
if count % BATCH_SIZE == 0:
    pg_cursor.executemany(sql, main_batch)  # InserciÃ³n masiva
    main_batch = []  # Limpiar para el siguiente lote
    pg_conn.commit()
```

## ğŸ› Problemas Resueltos

### 1. Timeout de Red Durante Migraciones Largas
**Problema**: Timeout del cursor de MongoDB despuÃ©s de 30 minutos de inactividad

**Error**:
```
pymongo.errors.NetworkTimeout: 10.100.20.142:27017: timed out
```

**SoluciÃ³n**: Agregado `no_cursor_timeout=True` a la creaciÃ³n del cursor
```python
documents_to_migrate = source_collection.find(no_cursor_timeout=True)
```

**Nota**: Mejora pendiente es usar sesiones explÃ­citas para control completo de timeout.

### 2. Sobrecarga de Salida en Consola
**Problema**: Cada documento procesado creaba una nueva lÃ­nea, haciendo los logs ilegibles

**SoluciÃ³n**: Retorno de carro con flush para actualizaciones en una sola lÃ­nea
```python
print(f"\r   -> Documentos procesados: {count}/{total_docs}", end="", flush=True)
```
- `\r` - Retorna el cursor al inicio de la lÃ­nea
- `end=""` - Previene salto de lÃ­nea
- `flush=True` - Fuerza salida inmediata (requerido para terminales bash)

### 3. Cuello de Botella de Rendimiento
**Problema**: EjecuciÃ³n inicial procesaba solo 400 documentos/minuto

**Causa RaÃ­z**: `process_user_data()` hacÃ­a 3-5 llamadas a la base de datos por documento, incluso para usuarios repetidos

**SoluciÃ³n**: Implementado cachÃ© en memoria (ver PatrÃ³n de CachÃ© arriba)

**Resultado**: Rendimiento mejorado a 2,000 documentos/minuto

### 4. Riesgo de DuplicaciÃ³n de Datos
**Problema**: Re-ejecutar el script podrÃ­a crear registros duplicados

**SoluciÃ³n**: ClÃ¡usula `ON CONFLICT DO NOTHING` en todas las inserciones
```python
INSERT INTO public.users (...) VALUES (...)
ON CONFLICT (id) DO NOTHING;
```
Esto hace el script **idempotente**: seguro para ejecutar mÃºltiples veces.

## âœ… Estado Actual

### QuÃ© EstÃ¡ Funcionando
- âœ… MigraciÃ³n completa de la colecciÃ³n `lml_processes_mesa4core` (123,084 documentos)
- âœ… Arquitectura de schema hÃ­brido implementada
- âœ… Rendimiento optimizado con cachÃ© y procesamiento por lotes
- âœ… Relaciones de claves forÃ¡neas apropiadas establecidas
- âœ… MigraciÃ³n idempotente (segura para re-ejecutar)
- âœ… Convenciones de nomenclatura semÃ¡ntica (`process_id` vs `mongo_id`)

### Resultados Verificados
- Base de datos: `mesamongo` creada y poblada
- Schema: `public` contiene 7 tablas de entidades compartidas
- Schema: `lml_processes` contiene 5 tablas especÃ­ficas de colecciÃ³n
- Integridad de datos: Todas las claves forÃ¡neas referencian apropiadamente las tablas padre

## ğŸ”® PrÃ³ximos Pasos

### Inmediatos (Requeridos Antes de la Siguiente ColecciÃ³n)

1. **Separar Setup de MigraciÃ³n**
   ```
   Actual:     mongomigra.py (crea tablas + migra datos)
   Requerido:  setup_database.py (crea tablas UNA VEZ)
               mongomigra.py (solo migra datos)
   ```
   **Por quÃ©**: `DROP TABLE CASCADE` destruye datos de colecciones previas

2. **Implementar Sistema de Reglas de MigraciÃ³n**
   Definir reglas especÃ­ficas por colecciÃ³n en `config.py`:
   ```python
   COLLECTION_RULES = {
       "lml_processes_mesa4core": {
           "primary_key_name": "process_id",
           "target_schema": "lml_processes",
           "shared_entities": ["users", "customers"],
           # ...
       }
   }
   ```

3. **Manejar Timeouts de SesiÃ³n de MongoDB**
   Implementar gestiÃ³n explÃ­cita de sesiÃ³n para prevenir advertencia de timeout de 30 minutos:
   ```python
   with mongo_client.start_session() as session:
       documents_to_migrate = source_collection.find(
           no_cursor_timeout=True,
           session=session
       )
   ```

### Mejoras Futuras

1. **Soporte Multi-ColecciÃ³n**
   - Descubrimiento/listado de colecciones
   - MigraciÃ³n paralela de colecciones independientes
   - Seguimiento de progreso y reanudaciÃ³n

2. **ValidaciÃ³n de Datos**
   - AnÃ¡lisis de schema pre-migraciÃ³n
   - Verificaciones de integridad de datos post-migraciÃ³n
   - ReconciliaciÃ³n de conteo de registros

3. **Manejo de Errores**
   - RecuperaciÃ³n elegante de fallos
   - Logging detallado de errores
   - Mecanismos de rollback

4. **Monitoreo y Reportes**
   - Dashboard de progreso de migraciÃ³n
   - MÃ©tricas de rendimiento
   - Reportes de calidad de datos

## ğŸ”‘ Comandos Ãštiles

### ConfiguraciÃ³n del Entorno
```bash
# Crear entorno virtual
python -m venv mongomigra

# Activar (Windows)
mongomigra\Scripts\activate

# Activar (Linux/Mac)
source mongomigra/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### Operaciones de Base de Datos
```bash
# Ejecutar migraciÃ³n
python mongomigra.py

# Verificar schema de PostgreSQL
psql -U <usuario> -d mesamongo -c "\dn"

# Verificar tablas en schema
psql -U <usuario> -d mesamongo -c "\dt lml_processes.*"

# Contar registros migrados
psql -U <usuario> -d mesamongo -c "SELECT COUNT(*) FROM lml_processes.main;"
```

### Desarrollo
```bash
# Agregar nueva dependencia
pip install <paquete>
pip freeze > requirements.txt

# Actualizar configuraciÃ³n
# Editar .env para secretos
# Editar config.py para parÃ¡metros no sensibles
```

## ğŸ” ConfiguraciÃ³n del Entorno

### Estructura de `.env`
```ini
# MongoDB
MONGO_HOST=
MONGO_PORT=
MONGO_USER=
MONGO_PASSWORD=
MONGO_AUTH_SOURCE=

# PostgreSQL
POSTGRES_DB=mesamongo
POSTGRES_HOST=
POSTGRES_PORT=
POSTGRES_USER=
POSTGRES_PASSWORD=
```

**Nota de Seguridad**: Nunca hacer commit de `.env` al control de versiones. Usar plantilla `.env.example` para compartir con el equipo.

## ğŸ“ Principios de DiseÃ±o Aplicados

### 1. Ãšnica Fuente de Verdad
Las entidades compartidas viven en el schema `public`, referenciadas por todos los schemas de colecciÃ³n vÃ­a claves forÃ¡neas.

### 2. Idempotencia
Todas las operaciones usan `ON CONFLICT DO NOTHING` para manejar re-ejecuciones de forma segura.

### 3. Rendimiento Primero
Operaciones de cachÃ© y por lotes minimizan viajes de ida y vuelta a la base de datos.

### 4. Claridad SemÃ¡ntica
Los nombres reflejan significado de negocio (`process_id`) no origen tÃ©cnico (`mongo_id`).

### 5. SeparaciÃ³n de Responsabilidades
- `config.py` - ConfiguraciÃ³n
- `mongomigra.py` - LÃ³gica de migraciÃ³n
- `.env` - Secretos

### 6. Arquitectura A Prueba de Futuro
El diseÃ±o de schema hÃ­brido escala a mÃºltiples colecciones sin conflictos.

## ğŸ“ Lecciones Aprendidas

### Insights TÃ©cnicos
1. **Procesamiento por Lotes**: Mejora de rendimiento de 250x sobre fila por fila
2. **CachÃ© en Memoria**: Esencial para bÃºsquedas de entidades repetidas
3. **Timeouts de Cursor**: Operaciones de larga duraciÃ³n necesitan manejo explÃ­cito de timeout
4. **Claves ForÃ¡neas**: Refuerzan integridad de datos pero requieren orden de inserciÃ³n cuidadoso

### Insights ArquitectÃ³nicos
1. **Schemas HÃ­bridos**: Lo mejor de dos mundos (organizaciÃ³n + entidades compartidas)
2. **Nomenclatura SemÃ¡ntica**: Reduce carga cognitiva y mejora mantenibilidad
3. **ExternalizaciÃ³n de ConfiguraciÃ³n**: Habilita flexibilidad sin cambios de cÃ³digo
4. **Scripts Idempotentes**: Seguridad en desarrollo y producciÃ³n

## ğŸ”„ Historial de Cambios Importantes

### v2.0 - RefactorizaciÃ³n de Nomenclatura SemÃ¡ntica
**Fecha**: 2025-11-05

**Cambios**:
- Renombrado de base de datos: `postgres` â†’ `mesamongo`
- Renombrado de columna: `mongo_id` â†’ `process_id`
- Renombrado de FK: `record_id` â†’ `process_id` (en todas las tablas relacionadas)
- Movimiento de entidad: `customer_id` de columna simple a FK â†’ `public.customers`

**JustificaciÃ³n**: Mejorar la claridad semÃ¡ntica y establecer patrones de nomenclatura consistentes para futuras colecciones.

### v1.0 - ImplementaciÃ³n Inicial de POC
**Fecha**: 2025-10-30 (aproximado)

**Logros**:
- MigraciÃ³n exitosa de primera colecciÃ³n
- ImplementaciÃ³n de arquitectura de schema hÃ­brido
- Optimizaciones de rendimiento (cachÃ© + batching)
- Manejo de timeout de cursor

### TecnologÃ­as Core
- **Python 3.12**: Lenguaje de programaciÃ³n principal
- **pymongo**: Driver y cliente de MongoDB
- **psycopg2**: Adaptador de PostgreSQL
- **python-dotenv**: GestiÃ³n de variables de entorno

### Sistemas de Base de Datos
- **MongoDB** (Origen): Base de datos NoSQL orientada a documentos
- **PostgreSQL** (Destino): Base de datos SQL relacional

---

## ğŸ“ Comandos Ãštiles de Referencia

### ConfiguraciÃ³n del Entorno
```bash
# Crear entorno virtual
python -m venv mongomigra

# Activar (Windows)
mongomigra\Scripts\activate

# Activar (Linux/Mac)
source mongomigra/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### Operaciones de Base de Datos
```bash
# Setup inicial (ejecutar UNA VEZ)
python dbsetup.py

# Ejecutar migraciÃ³n
python mongomigra.py

# Verificar schemas de PostgreSQL
psql -U <usuario> -d mesamongo -c "\dn"

# Verificar tablas en schema
psql -U <usuario> -d mesamongo -c "\dt lml_processes.*"

# Contar registros migrados
psql -U <usuario> -d mesamongo -c "SELECT COUNT(*) FROM lml_processes.main;"
```

### Desarrollo
```bash
# Exportar sample para anÃ¡lisis
python export_sample.py <collection_name> 200

# Analizar estructura de colecciÃ³n
python analyze_listbuilder.py

# Agregar nueva dependencia
pip install <paquete>
pip freeze > requirements.txt
```

---

## ğŸ“ Lecciones Aprendidas

### Insights TÃ©cnicos
1. **Procesamiento por Lotes**: Mejora de rendimiento de 250x sobre fila por fila
2. **CachÃ© en Memoria**: Esencial para bÃºsquedas de entidades repetidas (mejora 5x)
3. **Timeouts de Cursor**: Operaciones de larga duraciÃ³n necesitan `no_cursor_timeout=True`
4. **Claves ForÃ¡neas**: Refuerzan integridad de datos pero requieren orden de inserciÃ³n cuidadoso

### Insights ArquitectÃ³nicos
1. **Schemas HÃ­bridos**: Lo mejor de dos mundos (organizaciÃ³n + entidades compartidas)
2. **Nomenclatura SemÃ¡ntica**: Reduce carga cognitiva y mejora mantenibilidad
3. **ExternalizaciÃ³n de ConfiguraciÃ³n**: Habilita flexibilidad sin cambios de cÃ³digo
4. **Scripts Idempotentes**: Seguridad en desarrollo y producciÃ³n

### Patrones que Funcionaron Bien
- âœ… Strategy Pattern para migradores (BaseMigrator + implementaciones)
- âœ… Carga dinÃ¡mica de mÃ³dulos (evita modificar mongomigra.py)
- âœ… CachÃ© simple con `set()` (O(1) lookups)
- âœ… Batch processing con `executemany()`

### Errores Comunes Evitados
- ğŸš« NO usar `DROP TABLE CASCADE` en producciÃ³n
- ğŸš« NO asumir que todos los campos existen (usar `.get()`)
- ğŸš« NO hacer commit despuÃ©s de cada INSERT
- ğŸš« NO usar nombres tÃ©cnicos (`mongo_id`) cuando hay nombres semÃ¡nticos mejores

---

## ğŸ“‹ Principios de DiseÃ±o Aplicados

### 1. Ãšnica Fuente de Verdad
Las entidades compartidas viven en el schema `public`, referenciadas por todos los schemas de colecciÃ³n vÃ­a claves forÃ¡neas.

### 2. Idempotencia
Todas las operaciones usan `ON CONFLICT DO NOTHING` para manejar re-ejecuciones de forma segura.

### 3. Rendimiento Primero
Operaciones de cachÃ© y por lotes minimizan viajes de ida y vuelta a la base de datos.

### 4. Claridad SemÃ¡ntica
Los nombres reflejan significado de negocio (`process_id`) no origen tÃ©cnico (`mongo_id`).

### 5. SeparaciÃ³n de Responsabilidades
- `config.py` - ConfiguraciÃ³n
- `dbsetup.py` - Setup de estructura
- `mongomigra.py` - OrquestaciÃ³n de migraciÃ³n
- `migrators/*.py` - LÃ³gica especÃ­fica por colecciÃ³n
- `.env` - Secretos

### 6. Arquitectura A Prueba de Futuro
El diseÃ±o de schema hÃ­brido escala a mÃºltiples colecciones sin conflictos.

---

## ğŸ”„ Historial de Versiones

| VersiÃ³n | Fecha | Cambios Principales |
|---------|-------|---------------------|
| v1.0 | 2025-10-30 | POC inicial: migraciÃ³n monolÃ­tica de lml_processes |
| v2.0 | 2025-11-05 | RefactorizaciÃ³n: nomenclatura semÃ¡ntica (process_id vs mongo_id) |
| v3.0 | 2025-11-15 | Arquitectura multi-colecciÃ³n: BaseMigrator + carga dinÃ¡mica |
| v3.1 | 2025-01-19 | Segunda colecciÃ³n (lml_listbuilder) + documentaciÃ³n completa |

---

## ğŸš€ PrÃ³ximos Pasos

### Inmediatos
1. âœ… Separar setup de migraciÃ³n (dbsetup.py â‰  mongomigra.py) - COMPLETADO
2. âœ… Sistema de carga dinÃ¡mica de migradores - COMPLETADO
3. ğŸ”§ Migrar siguiente colecciÃ³n (TBD por prioridad de negocio)
4. ğŸ”§ Implementar tests de integridad automatizados

### Mejoras Futuras
1. **Soporte Multi-ColecciÃ³n Paralelo**
   - MigraciÃ³n paralela de colecciones independientes
   - Seguimiento de progreso y reanudaciÃ³n

2. **ValidaciÃ³n Automatizada**
   - AnÃ¡lisis de schema pre-migraciÃ³n
   - Verificaciones de integridad post-migraciÃ³n
   - ReconciliaciÃ³n de conteo de registros

3. **Manejo de Errores Robusto**
   - RecuperaciÃ³n elegante de fallos
   - Logging detallado de errores
   - Mecanismos de rollback

4. **IntegraciÃ³n con n8n**
   - Modo batch no-interactivo
   - SincronizaciÃ³n programada
   - Notificaciones automÃ¡ticas

---

## ğŸ“š Estructura de `.env`

```ini
# MongoDB
MONGO_HOST=
MONGO_PORT=
MONGO_USER=
MONGO_PASSWORD=
MONGO_AUTH_SOURCE=

# PostgreSQL
POSTGRES_DB=mesamongo
POSTGRES_HOST=
POSTGRES_PORT=
POSTGRES_USER=
POSTGRES_PASSWORD=
```

**âš ï¸ Nota de Seguridad**: Nunca hacer commit de `.env` al control de versiones. Usar plantilla `.env.example` para compartir con el equipo.

---

**Ãšltima ActualizaciÃ³n**: 2025-01-19  
**VersiÃ³n Actual**: v3.1 (Arquitectura multi-colecciÃ³n + documentaciÃ³n completa)  
**Estado**: 2/8 colecciones migradas, sistema listo para escalar  
**PrÃ³ximo Hito**: Migrar colecciÃ³n #3 siguiendo el workflow documentado  
**Colecciones Migradas**: 1 de ~N (pendiente determinar total)