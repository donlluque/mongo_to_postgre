r"""
Script principal de migraci√≥n de colecciones MongoDB a PostgreSQL.

Este script orquesta el proceso de migraci√≥n de datos desde MongoDB hacia
PostgreSQL. La l√≥gica espec√≠fica de transformaci√≥n est√° delegada a m√≥dulos
en el paquete 'migrators/', permitiendo migrar m√∫ltiples colecciones con
diferentes estructuras.

Arquitectura:
- mongomigra.py: Infraestructura (conexiones, batching, progreso)
- migrators/*.py: L√≥gica de transformaci√≥n espec√≠fica por colecci√≥n

Flujo de Ejecuci√≥n:
1. Conectar a MongoDB y PostgreSQL
2. Cargar m√≥dulo migrador espec√≠fico (migrators/lml_processes.py)
3. Iterar sobre documentos en batches
4. Extraer entidades compartidas (public.*)
5. Extraer datos espec√≠ficos (schema espec√≠fico)
6. Insertar en batches y commit

Prerrequisitos:
- Base de datos creada (mesamongo)
- Estructura de tablas creada (ejecutar dbsetup.py primero)

Uso:
    python mongomigra.py
    
    # Verificar migraci√≥n
    psql -d mesamongo -c "SELECT COUNT(*) FROM lml_processes.main;"

Optimizaciones:
- Batch processing: Inserciones de 500 registros por commit
- Cach√© en memoria: Evita procesamiento redundante de entidades compartidas
- Cursor sin timeout: Soporta migraciones de larga duraci√≥n
"""

import sys
import psycopg2
from pymongo import MongoClient, CursorType
from pymongo.errors import ConnectionFailure
from psycopg2 import OperationalError, ProgrammingError

import config
from migrators import lml_processes as migrator


def connect_to_mongo():
    """
    Establece conexi√≥n a MongoDB usando credenciales de config.py.
    
    Configuraci√≥n:
    - Timeout de selecci√≥n de servidor: 5 segundos
    - Ping inicial para validar conexi√≥n
    
    Returns:
        Database: Objeto de base de datos de pymongo
        
    Raises:
        ConnectionFailure: Si no puede conectar a MongoDB
        SystemExit: Termina el programa con c√≥digo 1
    """
    try:
        print("üîå Conectando a MongoDB...")
        client = MongoClient(config.MONGO_URI, serverSelectionTimeoutMS=5000)
        client.admin.command('ping')
        db = client[config.MONGO_DATABASE_NAME]
        print("‚úÖ Conexi√≥n a MongoDB exitosa")
        return db
    except ConnectionFailure as e:
        print(f"‚ùå Error de conexi√≥n a MongoDB", file=sys.stderr)
        print(f"   Detalle: {e}", file=sys.stderr)
        sys.exit(1)


def connect_to_postgres():
    """
    Establece conexi√≥n a PostgreSQL usando credenciales de config.py.
    
    Returns:
        tuple: (conexi√≥n, cursor) de psycopg2
        
    Raises:
        OperationalError: Si no puede conectar a PostgreSQL
        SystemExit: Termina el programa con c√≥digo 1
    """
    try:
        print("üîå Conectando a PostgreSQL...")
        conn = psycopg2.connect(**config.POSTGRES_CONFIG)
        cursor = conn.cursor()
        print("‚úÖ Conexi√≥n a PostgreSQL exitosa")
        return conn, cursor
    except OperationalError as e:
        print(f"‚ùå Error de conexi√≥n a PostgreSQL", file=sys.stderr)
        print(f"   Detalle: {e}", file=sys.stderr)
        sys.exit(1)


def migrate_collection(mongo_db, pg_cursor, pg_conn, collection_name):
    """
    Orquesta la migraci√≥n de una colecci√≥n espec√≠fica.
    
    Esta funci√≥n maneja:
    - Iteraci√≥n sobre documentos de MongoDB
    - Acumulaci√≥n de registros en batches
    - Coordinaci√≥n con el m√≥dulo migrador espec√≠fico
    - Commits peri√≥dicos a PostgreSQL
    - Reporte de progreso
    
    El patr√≥n de procesamiento es:
        Para cada documento:
            1. Extraer entidades compartidas ‚Üí INSERT en public.*
            2. Extraer datos espec√≠ficos ‚Üí Acumular en batches
            3. Cada N documentos ‚Üí executemany() + commit
    
    Args:
        mongo_db: Base de datos de pymongo
        pg_cursor: Cursor de psycopg2
        pg_conn: Conexi√≥n de psycopg2
        collection_name: Nombre de la colecci√≥n a migrar
        
    Raises:
        KeyError: Si collection_name no existe en config.COLLECTIONS
    """
    print(f"\nüöö Iniciando migraci√≥n de colecci√≥n '{collection_name}'...")
    
    # Validar que la colecci√≥n est√© configurada
    if collection_name not in config.COLLECTIONS:
        print(f"‚ùå Colecci√≥n '{collection_name}' no encontrada en config.COLLECTIONS", file=sys.stderr)
        sys.exit(1)
    
    collection_config = config.COLLECTIONS[collection_name]
    schema = collection_config['postgres_schema']
    
    source_collection = mongo_db[collection_name]
    batch_size = config.BATCH_SIZE
    
    # Contar documentos totales
    total_docs = source_collection.count_documents({})
    if total_docs == 0:
        print(f"‚ö†Ô∏è  Advertencia: No se encontraron documentos en '{collection_name}'")
        return
    
    print(f"   üìä Total de documentos: {total_docs:,}")
    print(f"   üì¶ Tama√±o de batch: {batch_size}")
    print(f"   üéØ Schema destino: {schema}")
    
    # Inicializar cach√©s para evitar procesamiento redundante
    caches = {
        'users': set(),
        'areas': set(),
        'subareas': set(),
        'roles': set(),
        'groups': set(),
        'customers': set()
    }
    
    # Inicializar batches acumuladores
    main_batch = []
    movements_batch = []
    initiator_fields_batch = []
    documents_batch = []
    last_movements_batch = []
    
    # Cursor sin timeout para migraciones largas (>30 min)
    documents_to_migrate = source_collection.find(
        cursor_type=CursorType.NON_TAILABLE
    )
    count = 0
    
    try:
        for doc in documents_to_migrate:
            count += 1
            process_id = str(doc.get('_id'))
            
            # PASO 1: Extraer y procesar entidades compartidas
            # Esto inserta directamente en public.* usando ON CONFLICT
            shared_entities = migrator.extract_shared_entities(doc, pg_cursor, caches)
            
            # PASO 2: Extraer datos espec√≠ficos (acumular en batches)
            main_batch.append(migrator.extract_main_record(doc, shared_entities))
            movements_batch.extend(migrator.extract_movements(doc, process_id))
            initiator_fields_batch.extend(migrator.extract_initiator_fields(doc, process_id))
            documents_batch.extend(migrator.extract_documents(doc, process_id))
            
            last_movement = migrator.extract_last_movement(doc, process_id)
            if last_movement:
                last_movements_batch.append(last_movement)
            
            # Mostrar progreso en la misma l√≠nea
            if count % 100 == 0 or count % batch_size == 0:
                print(f"\r   ‚è≥ Procesados: {count:,}/{total_docs:,} ({count*100//total_docs}%)", end="", flush=True)
            
            # PASO 3: Insertar y commit cada N documentos
            if count % batch_size == 0:
                migrator.insert_main_batch(main_batch, pg_cursor, schema)
                migrator.insert_movements_batch(movements_batch, pg_cursor, schema)
                migrator.insert_initiator_fields_batch(initiator_fields_batch, pg_cursor, schema)
                migrator.insert_documents_batch(documents_batch, pg_cursor, schema)
                migrator.insert_last_movements_batch(last_movements_batch, pg_cursor, schema)
                
                pg_conn.commit()
                
                # Limpiar batches para el pr√≥ximo ciclo
                main_batch = []
                movements_batch = []
                initiator_fields_batch = []
                documents_batch = []
                last_movements_batch = []
        
        # PASO 4: Insertar registros finales (si count no es m√∫ltiplo exacto de batch_size)
        print("\n   üíæ Insertando registros finales...")
        migrator.insert_main_batch(main_batch, pg_cursor, schema)
        migrator.insert_movements_batch(movements_batch, pg_cursor, schema)
        migrator.insert_initiator_fields_batch(initiator_fields_batch, pg_cursor, schema)
        migrator.insert_documents_batch(documents_batch, pg_cursor, schema)
        migrator.insert_last_movements_batch(last_movements_batch, pg_cursor, schema)
        
        pg_conn.commit()
        
        print(f"\n‚úÖ Migraci√≥n completada: {count:,} documentos procesados")
        
        # Reporte de entidades compartidas procesadas
        print(f"\nüìã Resumen de entidades compartidas:")
        print(f"   üë• Usuarios: {len(caches['users']):,}")
        print(f"   üè¢ √Åreas: {len(caches['areas']):,}")
        print(f"   üìÅ Subareas: {len(caches['subareas']):,}")
        print(f"   üé≠ Roles: {len(caches['roles']):,}")
        print(f"   üë™ Grupos: {len(caches['groups']):,}")
        print(f"   üè™ Clientes: {len(caches['customers']):,}")
        
    finally:
        # Cerrar cursor de MongoDB para liberar recursos
        documents_to_migrate.close()


def main():
    """
    Funci√≥n principal que coordina el flujo completo de migraci√≥n.
    
    Secuencia:
    1. Conectar a ambas bases de datos
    2. Ejecutar migraci√≥n de colecci√≥n configurada
    3. Cerrar conexiones limpiamente
    
    Exit Codes:
        0: √âxito
        1: Error de conexi√≥n o migraci√≥n
    """
    print("=" * 70)
    print("üöÄ SISTEMA DE MIGRACI√ìN MONGODB ‚Üí POSTGRESQL")
    print("=" * 70)
    print(f"üìç MongoDB: {config.MONGO_DATABASE_NAME}")
    print(f"üìç PostgreSQL: {config.POSTGRES_CONFIG['dbname']}")
    print("=" * 70)
    
    # Por ahora migramos solo lml_processes, despu√©s ser√° parametrizable
    collection_name = "lml_processes_mesa4core"
    
    mongo_db = connect_to_mongo()
    pg_conn, pg_cursor = connect_to_postgres()
    
    try:
        migrate_collection(mongo_db, pg_cursor, pg_conn, collection_name)
        
        print("\n" + "=" * 70)
        print("‚úÖ PROCESO COMPLETADO EXITOSAMENTE")
        print("=" * 70)
        
    except Exception as e:
        print(f"\n‚ùå Error durante la migraci√≥n: {e}", file=sys.stderr)
        pg_conn.rollback()
        sys.exit(1)
        
    finally:
        print("\nüîí Cerrando conexiones...")
        pg_cursor.close()
        pg_conn.close()
        print("‚úÖ Conexiones cerradas correctamente")


if __name__ == "__main__":
    main()