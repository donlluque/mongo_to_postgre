# Proyecto de Migraci√≥n MongoDB a PostgreSQL - Contexto Completo

## üìã Visi√≥n General del Proyecto

### Prop√≥sito y Visi√≥n
Este proyecto implementa un sistema completo de migraci√≥n desde una base de datos MongoDB (`mesa4core`) hacia una base de datos PostgreSQL relacional (`mesamongo`). El objetivo no es simplemente transferir datos, sino **transformarlos** de un modelo de documentos NoSQL con estructuras anidadas a un modelo relacional propiamente normalizado siguiendo las mejores pr√°cticas de dise√±o de bases de datos.

### ¬øPor qu√© esta migraci√≥n?
La decisi√≥n de migrar desde MongoDB hacia PostgreSQL responde a varias necesidades:

1. **Integridad de Datos**: Implementar integridad referencial mediante claves for√°neas y restricciones
2. **Normalizaci√≥n**: Eliminar la duplicaci√≥n de datos inherente al modelo desnormalizado de MongoDB
3. **Consultas Complejas**: Habilitar JOINs eficientes y consultas relacionales complejas
4. **Estandarizaci√≥n**: Consolidar entidades compartidas (usuarios, √°reas, clientes) en tablas de √∫nica fuente de verdad

## üèóÔ∏è Arquitectura T√©cnica

### Dise√±o de Esquemas H√≠brido
La arquitectura implementa un **patr√≥n de esquemas h√≠bridos** en PostgreSQL:

#### Schema Public (Entidades Compartidas)
Aloja entidades que se reutilizan a trav√©s de m√∫ltiples colecciones:
- `public.users` - Usuarios del sistema
- `public.areas` - √Åreas organizacionales
- `public.subareas` - Subdivisiones de √°reas
- `public.roles` - Roles de usuario
- `public.groups` - Grupos de usuarios
- `public.user_groups` - Tabla de relaci√≥n muchos-a-muchos
- `public.customers` - Clientes (a√±adida recientemente)

#### Schemas Espec√≠ficos por Colecci√≥n
Cada colecci√≥n de MongoDB obtiene su propio schema para datos espec√≠ficos:
- Schema `lml_processes` contiene:
  - `main` - Registros principales de procesos
  - `movements` - Historial de movimientos de procesos
  - `last_movements` - √öltimo movimiento por proceso
  - `initiator_fields` - Campos din√°micos del iniciador del proceso
  - `process_documents` - Documentos asociados

### ¬øPor qu√© H√≠brido vs. Schema √önico?
Esta arquitectura proporciona:
- **Organizaci√≥n**: Separaci√≥n clara entre datos compartidos y espec√≠ficos de colecci√≥n
- **Escalabilidad**: Nuevas colecciones pueden agregarse sin colisiones de nombres
- **Mantenibilidad**: F√°cil de entender la propiedad de los datos
- **Flexibilidad**: Futuras colecciones pueden reutilizar entidades p√∫blicas o crear nuevas

## üîß Stack Tecnol√≥gico

### Tecnolog√≠as Core
- **Python 3.12**: Lenguaje de programaci√≥n principal
- **pymongo**: Driver y cliente de MongoDB
- **psycopg2**: Adaptador de PostgreSQL
- **python-dotenv**: Gesti√≥n de variables de entorno

### Sistemas de Base de Datos
- **MongoDB** (Origen): Base de datos NoSQL orientada a documentos
- **PostgreSQL** (Destino): Base de datos SQL relacional

## üìä Transformaci√≥n del Modelo de Datos

### Estructura MongoDB (Original)
Los documentos en la colecci√≥n `lml_processes_mesa4core` contienen objetos profundamente anidados:

```javascript
{
  _id: ObjectId("..."),
  processNumber: "12345",
  customerId: "CUST001",
  createdBy: {
    user: {
      id: "USR001",
      email: "usuario@ejemplo.com",
      firstname: "Juan",
      lastname: "P√©rez",
      area: { id: "AREA01", name: "Operaciones" },
      subarea: { id: "SUB01", name: "Log√≠stica" },
      role: { id: "ROLE01", name: "Gerente" },
      groups: [{ id: "GRP01", name: "Administradores" }]
    }
  },
  movements: [
    { at: ISODate("..."), id: "MOV001", to: "destino" }
  ],
  initiatorFields: {
    campo1: { id: "FLD01", name: "Campo Uno" }
  }
}
```

### Estructura PostgreSQL (Transformada)

#### Entidades Compartidas (schema public)
```sql
public.users (
  id VARCHAR(255) PRIMARY KEY,
  email VARCHAR(255) UNIQUE,
  firstname VARCHAR(255),
  lastname VARCHAR(255),
  area_id VARCHAR(255) ‚Üí public.areas(id),
  subarea_id VARCHAR(255) ‚Üí public.subareas(id),
  role_id VARCHAR(255) ‚Üí public.roles(id)
)

public.customers (
  id VARCHAR(255) PRIMARY KEY
)
```

#### Espec√≠fico de Colecci√≥n (schema lml_processes)
```sql
lml_processes.main (
  process_id VARCHAR(255) PRIMARY KEY,  -- Anteriormente mongo_id
  process_number VARCHAR(255),
  customer_id VARCHAR(255) ‚Üí public.customers(id),
  created_by_user_id VARCHAR(255) ‚Üí public.users(id),
  updated_by_user_id VARCHAR(255) ‚Üí public.users(id),
  ...
)

lml_processes.movements (
  id SERIAL PRIMARY KEY,
  process_id VARCHAR(255) ‚Üí lml_processes.main(process_id),  -- Anteriormente record_id
  movement_at TIMESTAMP,
  destination_id VARCHAR(255),
  destination_type VARCHAR(50)
)
```

### Convenciones de Nomenclatura Clave
Las mejoras recientes establecen patrones claros:

1. **Claves Primarias**: Usar nombres sem√°nticos (`process_id` no `mongo_id`)
2. **Claves For√°neas**: Coincidir con nombres de claves primarias referenciadas (`process_id` no `record_id`)
3. **Consistencia**: La misma entidad se referencia de la misma forma en todos lados

## üìú Scripts Actuales

### `config.py` - Gesti√≥n de Configuraci√≥n
Centraliza toda la configuraci√≥n no sensible:

```python
# Detalles de conexi√≥n MongoDB
MONGO_URI  # Construido desde variables de entorno
MONGO_DATABASE_NAME = "mesa4core"
MONGO_SOURCE_COLLECTION = "lml_processes_mesa4core"

# Detalles de conexi√≥n PostgreSQL
POSTGRES_CONFIG = {
    'dbname': os.getenv('POSTGRES_DB'),  # "mesamongo"
    # ... otros par√°metros de conexi√≥n
}

# Mapeos de nombres de tablas
TABLE_NAMES = { ... }

# Configuraci√≥n de migraci√≥n
POC_SCHEMA_NAME = "lml_processes"
BATCH_SIZE = 500  # Registros por inserci√≥n en lote
```

**Decisi√≥n de Dise√±o**: Separar la configuraci√≥n de la l√≥gica permite:
- Ajustes f√°ciles sin cambios de c√≥digo
- Futura conversi√≥n a archivos de configuraci√≥n (JSON/YAML)
- Documentaci√≥n clara de los par√°metros del sistema

### `mongomigra.py` - Motor de Migraci√≥n
El script principal de migraci√≥n implementa:

#### 1. Gesti√≥n de Conexiones
```python
def connect_to_mongo()
def connect_to_postgres()
```
Establecen conexiones con manejo de errores apropiado y configuraci√≥n de timeouts.

#### 2. Creaci√≥n de Schema
```python
def create_postgres_tables(pg_cursor, pg_conn)
```
Crea la estructura completa del schema h√≠brido. Actualmente usa `DROP TABLE CASCADE` para migraciones de pizarra limpia.

**Importante**: Esto es aceptable para POC pero debe refactorizarse para producci√≥n (ver Mejoras Futuras).

#### 3. Procesamiento de Entidades con Cach√©
```python
def process_user_data(user_obj, pg_cursor, caches)
def process_customer_data(customer_id, pg_cursor, caches)
```

**El Patr√≥n de Cach√©**: Optimizaci√≥n cr√≠tica de rendimiento
- **Problema**: Sin cach√©, cada documento procesa usuarios redundantemente
- **Soluci√≥n**: `set()` en memoria rastrea entidades ya procesadas
- **Impacto**: Mejora de velocidad de ~5x (2,000 docs/min vs. 400 docs/min)

```python
caches = {
    'users': set(),
    'customers': set(),
    # ... otras entidades
}

# Ruta r√°pida: b√∫squeda O(1)
if user_id in caches['users']:
    return user_id  # Saltar operaci√≥n de base de datos

# Ruta lenta: Insertar en base de datos
pg_cursor.execute("INSERT INTO public.users ...")
caches['users'].add(user_id)  # Recordar para la pr√≥xima vez
```

#### 4. Migraci√≥n por Lotes
```python
def migrate_collection(mongo_db, pg_cursor, pg_conn)
```

**Estrategia de Procesamiento por Lotes**:
- Acumula registros en listas en memoria (ej., `main_batch`, `movements_batch`)
- Inserta en lotes de 500 usando `executemany()`
- Hace commit de cada lote a la base de datos

**¬øPor qu√© por Lotes?**
- `INSERT` √∫nico: ~10-50ms por registro = 20 registros/segundo
- `INSERT` por lotes: ~100ms por 500 registros = 5,000 registros/segundo
- Overhead de red reducido en ~99%

```python
if count % BATCH_SIZE == 0:
    pg_cursor.executemany(sql, main_batch)  # Inserci√≥n masiva
    main_batch = []  # Limpiar para el siguiente lote
    pg_conn.commit()
```

## üêõ Problemas Resueltos

### 1. Timeout de Red Durante Migraciones Largas
**Problema**: Timeout del cursor de MongoDB despu√©s de 30 minutos de inactividad

**Error**:
```
pymongo.errors.NetworkTimeout: 10.100.20.142:27017: timed out
```

**Soluci√≥n**: Agregado `no_cursor_timeout=True` a la creaci√≥n del cursor
```python
documents_to_migrate = source_collection.find(no_cursor_timeout=True)
```

**Nota**: Mejora pendiente es usar sesiones expl√≠citas para control completo de timeout.

### 2. Sobrecarga de Salida en Consola
**Problema**: Cada documento procesado creaba una nueva l√≠nea, haciendo los logs ilegibles

**Soluci√≥n**: Retorno de carro con flush para actualizaciones en una sola l√≠nea
```python
print(f"\r   -> Documentos procesados: {count}/{total_docs}", end="", flush=True)
```
- `\r` - Retorna el cursor al inicio de la l√≠nea
- `end=""` - Previene salto de l√≠nea
- `flush=True` - Fuerza salida inmediata (requerido para terminales bash)

### 3. Cuello de Botella de Rendimiento
**Problema**: Ejecuci√≥n inicial procesaba solo 400 documentos/minuto

**Causa Ra√≠z**: `process_user_data()` hac√≠a 3-5 llamadas a la base de datos por documento, incluso para usuarios repetidos

**Soluci√≥n**: Implementado cach√© en memoria (ver Patr√≥n de Cach√© arriba)

**Resultado**: Rendimiento mejorado a 2,000 documentos/minuto

### 4. Riesgo de Duplicaci√≥n de Datos
**Problema**: Re-ejecutar el script podr√≠a crear registros duplicados

**Soluci√≥n**: Cl√°usula `ON CONFLICT DO NOTHING` en todas las inserciones
```python
INSERT INTO public.users (...) VALUES (...)
ON CONFLICT (id) DO NOTHING;
```
Esto hace el script **idempotente**: seguro para ejecutar m√∫ltiples veces.

## ‚úÖ Estado Actual

### Qu√© Est√° Funcionando
- ‚úÖ Migraci√≥n completa de la colecci√≥n `lml_processes_mesa4core` (123,084 documentos)
- ‚úÖ Arquitectura de schema h√≠brido implementada
- ‚úÖ Rendimiento optimizado con cach√© y procesamiento por lotes
- ‚úÖ Relaciones de claves for√°neas apropiadas establecidas
- ‚úÖ Migraci√≥n idempotente (segura para re-ejecutar)
- ‚úÖ Convenciones de nomenclatura sem√°ntica (`process_id` vs `mongo_id`)

### Resultados Verificados
- Base de datos: `mesamongo` creada y poblada
- Schema: `public` contiene 7 tablas de entidades compartidas
- Schema: `lml_processes` contiene 5 tablas espec√≠ficas de colecci√≥n
- Integridad de datos: Todas las claves for√°neas referencian apropiadamente las tablas padre

## üîÆ Pr√≥ximos Pasos

### Inmediatos (Requeridos Antes de la Siguiente Colecci√≥n)

1. **Separar Setup de Migraci√≥n**
   ```
   Actual:     mongomigra.py (crea tablas + migra datos)
   Requerido:  setup_database.py (crea tablas UNA VEZ)
               mongomigra.py (solo migra datos)
   ```
   **Por qu√©**: `DROP TABLE CASCADE` destruye datos de colecciones previas

2. **Implementar Sistema de Reglas de Migraci√≥n**
   Definir reglas espec√≠ficas por colecci√≥n en `config.py`:
   ```python
   COLLECTION_RULES = {
       "lml_processes_mesa4core": {
           "primary_key_name": "process_id",
           "target_schema": "lml_processes",
           "shared_entities": ["users", "customers"],
           # ...
       }
   }
   ```

3. **Manejar Timeouts de Sesi√≥n de MongoDB**
   Implementar gesti√≥n expl√≠cita de sesi√≥n para prevenir advertencia de timeout de 30 minutos:
   ```python
   with mongo_client.start_session() as session:
       documents_to_migrate = source_collection.find(
           no_cursor_timeout=True,
           session=session
       )
   ```

### Mejoras Futuras

1. **Soporte Multi-Colecci√≥n**
   - Descubrimiento/listado de colecciones
   - Migraci√≥n paralela de colecciones independientes
   - Seguimiento de progreso y reanudaci√≥n

2. **Validaci√≥n de Datos**
   - An√°lisis de schema pre-migraci√≥n
   - Verificaciones de integridad de datos post-migraci√≥n
   - Reconciliaci√≥n de conteo de registros

3. **Manejo de Errores**
   - Recuperaci√≥n elegante de fallos
   - Logging detallado de errores
   - Mecanismos de rollback

4. **Monitoreo y Reportes**
   - Dashboard de progreso de migraci√≥n
   - M√©tricas de rendimiento
   - Reportes de calidad de datos

## üîë Comandos √ötiles

### Configuraci√≥n del Entorno
```bash
# Crear entorno virtual
python -m venv mongomigra

# Activar (Windows)
mongomigra\Scripts\activate

# Activar (Linux/Mac)
source mongomigra/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### Operaciones de Base de Datos
```bash
# Ejecutar migraci√≥n
python mongomigra.py

# Verificar schema de PostgreSQL
psql -U <usuario> -d mesamongo -c "\dn"

# Verificar tablas en schema
psql -U <usuario> -d mesamongo -c "\dt lml_processes.*"

# Contar registros migrados
psql -U <usuario> -d mesamongo -c "SELECT COUNT(*) FROM lml_processes.main;"
```

### Desarrollo
```bash
# Agregar nueva dependencia
pip install <paquete>
pip freeze > requirements.txt

# Actualizar configuraci√≥n
# Editar .env para secretos
# Editar config.py para par√°metros no sensibles
```

## üîê Configuraci√≥n del Entorno

### Estructura de `.env`
```ini
# MongoDB
MONGO_HOST=
MONGO_PORT=
MONGO_USER=
MONGO_PASSWORD=
MONGO_AUTH_SOURCE=

# PostgreSQL
POSTGRES_DB=mesamongo
POSTGRES_HOST=
POSTGRES_PORT=
POSTGRES_USER=
POSTGRES_PASSWORD=
```

**Nota de Seguridad**: Nunca hacer commit de `.env` al control de versiones. Usar plantilla `.env.example` para compartir con el equipo.

## üìù Principios de Dise√±o Aplicados

### 1. √önica Fuente de Verdad
Las entidades compartidas viven en el schema `public`, referenciadas por todos los schemas de colecci√≥n v√≠a claves for√°neas.

### 2. Idempotencia
Todas las operaciones usan `ON CONFLICT DO NOTHING` para manejar re-ejecuciones de forma segura.

### 3. Rendimiento Primero
Operaciones de cach√© y por lotes minimizan viajes de ida y vuelta a la base de datos.

### 4. Claridad Sem√°ntica
Los nombres reflejan significado de negocio (`process_id`) no origen t√©cnico (`mongo_id`).

### 5. Separaci√≥n de Responsabilidades
- `config.py` - Configuraci√≥n
- `mongomigra.py` - L√≥gica de migraci√≥n
- `.env` - Secretos

### 6. Arquitectura A Prueba de Futuro
El dise√±o de schema h√≠brido escala a m√∫ltiples colecciones sin conflictos.

## üéì Lecciones Aprendidas

### Insights T√©cnicos
1. **Procesamiento por Lotes**: Mejora de rendimiento de 250x sobre fila por fila
2. **Cach√© en Memoria**: Esencial para b√∫squedas de entidades repetidas
3. **Timeouts de Cursor**: Operaciones de larga duraci√≥n necesitan manejo expl√≠cito de timeout
4. **Claves For√°neas**: Refuerzan integridad de datos pero requieren orden de inserci√≥n cuidadoso

### Insights Arquitect√≥nicos
1. **Schemas H√≠bridos**: Lo mejor de dos mundos (organizaci√≥n + entidades compartidas)
2. **Nomenclatura Sem√°ntica**: Reduce carga cognitiva y mejora mantenibilidad
3. **Externalizaci√≥n de Configuraci√≥n**: Habilita flexibilidad sin cambios de c√≥digo
4. **Scripts Idempotentes**: Seguridad en desarrollo y producci√≥n

## üîÑ Historial de Cambios Importantes

### v2.0 - Refactorizaci√≥n de Nomenclatura Sem√°ntica
**Fecha**: 2025-11-05

**Cambios**:
- Renombrado de base de datos: `postgres` ‚Üí `mesamongo`
- Renombrado de columna: `mongo_id` ‚Üí `process_id`
- Renombrado de FK: `record_id` ‚Üí `process_id` (en todas las tablas relacionadas)
- Movimiento de entidad: `customer_id` de columna simple a FK ‚Üí `public.customers`

**Justificaci√≥n**: Mejorar la claridad sem√°ntica y establecer patrones de nomenclatura consistentes para futuras colecciones.

### v1.0 - Implementaci√≥n Inicial de POC
**Fecha**: 2025-10-30 (aproximado)

**Logros**:
- Migraci√≥n exitosa de primera colecci√≥n
- Implementaci√≥n de arquitectura de schema h√≠brido
- Optimizaciones de rendimiento (cach√© + batching)
- Manejo de timeout de cursor

---

**√öltima Actualizaci√≥n**: 2025-11-05  
**Versi√≥n Actual**: v2.0 (Post-refactorizaci√≥n con nomenclatura sem√°ntica)  
**Estado**: Listo para producci√≥n de colecci√≥n √∫nica, necesita refactorizaci√≥n de setup para multi-colecci√≥n  
**Colecciones Migradas**: 1 de ~N (pendiente determinar total)